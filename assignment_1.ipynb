{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "assignment_1.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqNpRrF32WBE",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 1\n",
        "\n",
        "Using text http://www.gutenberg.org/files/2600/2600-0.txt\n",
        "1. Make text lowercase and remove all punctuation except spaces and dots.\n",
        "2. Tokenize text by BPE with vocab_size = 100\n",
        "3. Train 3-gram language model with laplace smoothing $\\delta=1$\n",
        "4. Using beam search with k=10 generate sequences of length=10 conditioned on provided inputs. Treat dots as terminal tokens.\n",
        "5. Calculate perplexity of the language model for the first sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9s3fh7eq3J4c",
        "colab_type": "code",
        "outputId": "f7d0cbc4-bb1d-4db7-d2a9-a362afe10764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!wget -O peace.txt http://www.gutenberg.org/files/2600/2600-0.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-07 19:59:15--  http://www.gutenberg.org/files/2600/2600-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3359549 (3.2M) [text/plain]\n",
            "Saving to: ‘peace.txt’\n",
            "\n",
            "\rpeace.txt             0%[                    ]       0  --.-KB/s               \rpeace.txt             1%[                    ]  60.51K   223KB/s               \rpeace.txt             6%[>                   ] 210.40K   387KB/s               \rpeace.txt            15%[==>                 ] 515.35K   631KB/s               \rpeace.txt            38%[======>             ]   1.23M  1.14MB/s               \rpeace.txt            91%[=================>  ]   2.95M  2.17MB/s               \rpeace.txt           100%[===================>]   3.20M  2.35MB/s    in 1.4s    \n",
            "\n",
            "2019-10-07 19:59:17 (2.35 MB/s) - ‘peace.txt’ saved [3359549/3359549]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gy59iph2WBH",
        "colab_type": "code",
        "outputId": "fb6a4f23-2fc8-4546-9351-74892dee8000",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "text = open('peace.txt', 'r').read()[2:]\n",
        "len(text)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3227579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhVYsg9g2WBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \n",
        "    text = text.lower()\n",
        "    \n",
        "    punctuation = string.punctuation.replace('.', '') + '—“”‘’'\n",
        "    translator = text.maketrans(punctuation, len(punctuation) * ' ')\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    text = re.sub('\\s+', ' ', text)\n",
        "\n",
        "    return text\n",
        "\n",
        "text = preprocess_text(text)\n",
        "assert len(text) == 3141169"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gqCZbGi2WBU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = text.split('.')\n",
        "text = [x.strip() for x in text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "VtEocJtD2WBa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from nltk import bigrams\n",
        "from sklearn.base import TransformerMixin\n",
        "import itertools\n",
        "from copy import deepcopy\n",
        "\n",
        "\n",
        "\n",
        "class BPE(TransformerMixin):\n",
        "    def __init__(self, vocab_size=100):\n",
        "        super(BPE, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        # index to token\n",
        "        self.itos = []\n",
        "        # token to index\n",
        "        self.stoi = {}\n",
        "        \n",
        "    def fit(self, text):\n",
        "        \"\"\"\n",
        "        fit itos and stoi\n",
        "        text: list of strings \n",
        "        \"\"\"\n",
        "        \n",
        "        # tokenize text by symbols and fill in self.itos and self.stoi\n",
        "        text_copy = deepcopy(\" \".join(text))\n",
        "        self.itos = list(set(text_copy))\n",
        "        self.stoi = {element : index for index,element in enumerate(self.itos)}\n",
        "        \n",
        "        text = [[self.stoi[char] for char in element]for element in text]   \n",
        "        \n",
        "        while len(self.itos) < self.vocab_size:\n",
        "            # TODO\n",
        "            # count bigram freqencies in the text\n",
        "            elements = list(itertools.chain.from_iterable(text_copy))\n",
        "            bigrams_ = Counter(list(bigrams(elements)))\n",
        "            new_token = ''.join(list(bigrams_.most_common(1)[0][0]))\n",
        "            new_id = len(self.itos)\n",
        "            \n",
        "            self.itos.append(new_token)\n",
        "            self.stoi[new_token] = new_id\n",
        "            \n",
        "            # find occurences of the new_token in the text and replace them with new_id\n",
        "            for index, element in enumerate(text):\n",
        "              count = 0\n",
        "              while count < len(element) -1:\n",
        "                temp = element[count] + element[count+1]\n",
        "                if temp == new_token:\n",
        "                  text[index][count] = new_id\n",
        "                  del text[index][count+1]\n",
        "                count += 1\n",
        "            \n",
        "        return self\n",
        "    \n",
        "    def transform(self, text):\n",
        "        \"\"\"\n",
        "        convert text to a sequence of token ids\n",
        "        text: list of strings\n",
        "        \"\"\"\n",
        "        text = [[self.stoi[char] for char in element]for element in text]\n",
        "        for token_id, token in enumerate(self.itos):\n",
        "            for index, element in enumerate(text):\n",
        "              count = 0\n",
        "              while count < len(element) -1:\n",
        "                temp = element[count] + element[count+1]\n",
        "                if temp == token:\n",
        "                  text[index][count] = token_id\n",
        "                  del text[index][count+1]\n",
        "                count += 1      \n",
        "        return text\n",
        "    \n",
        "    def decode_token(self, tok):\n",
        "        \"\"\"\n",
        "        tok: int or tuple\n",
        "        \"\"\"\n",
        "        if isinstance(tok, int):\n",
        "          result = self.itos[tok] \n",
        "        else:\n",
        "          result = [self.itos[i] for i in tok]\n",
        "        return result\n",
        "            \n",
        "    def decode(self, text):\n",
        "        \"\"\"\n",
        "        convert token ids into text\n",
        "        \"\"\"\n",
        "        return ''.join(map(self.decode_token, text))\n",
        "        \n",
        "        \n",
        "vocab_size = 100\n",
        "bpe = BPE(vocab_size)\n",
        "tokenized_text = bpe.fit_transform(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BM0-acPM2WBf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert bpe.decode(tokenized_text[0]) == text[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMRLktjw2WBj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from nltk import trigrams\n",
        "    \n",
        "start_token = vocab_size\n",
        "end_token = vocab_size + 1\n",
        "        \n",
        "    \n",
        "class LM:\n",
        "    def __init__(self, vocab_size, delta=1):\n",
        "        self.delta = delta\n",
        "        self.vocab_size = vocab_size + 2\n",
        "        self.proba = np.zeros((self.vocab_size, self.vocab_size, self.vocab_size))\n",
        "        \n",
        "    def infer(self, a, b, tau=1):\n",
        "        \"\"\"\n",
        "        return vector of probabilities of size self.vocab for 3-grams which start with (a,b) tokens\n",
        "        a: first token id\n",
        "        b: second token id\n",
        "        tau: temperature\n",
        "        \"\"\"\n",
        "        result = np.array([self.get_proba(a,b, i, tau) for i in range(self.vocab_size)])\n",
        "        return result\n",
        "        \n",
        "    def get_proba(self, a, b, c, tau=1):\n",
        "        \"\"\"\n",
        "        get probability of 3-gram (a,b,c)\n",
        "        a: first token id\n",
        "        b: second token id\n",
        "        c: third token id\n",
        "        tau: temperature\n",
        "        \"\"\"\n",
        "        \n",
        "        result = (self.proba[(a,b,c)] + self.delta) ** (1/tau) / sum (\n",
        "            [(self.proba[(a,b,x)] + self.delta)**(1/tau) for x in \n",
        "             range(self.vocab_size)])\n",
        "        return result\n",
        "    \n",
        "    def fit(self, text):\n",
        "        \"\"\"\n",
        "        train language model on text\n",
        "        text: list of lists\n",
        "        \"\"\"\n",
        "        \n",
        "        temp = Counter()\n",
        "        for element in text:\n",
        "         line = [start_token] + element + [end_token]\n",
        "         temp.update(nltk.trigrams(line))\n",
        "        self.proba = temp        \n",
        "        return self\n",
        "    \n",
        "lm = LM(vocab_size, 1).fit(tokenized_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKR3MGeO2WBm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def beam_search(input_seq, lm, max_len=10, k=5, tau=1):\n",
        "    \"\"\"\n",
        "    generate sequence from language model *lm* conditioned on input_seq\n",
        "    input_seq: sequence of token ids for conditioning\n",
        "    lm: language model\n",
        "    max_len: max generated sequence length\n",
        "    k: size of beam\n",
        "    tau: temperature\n",
        "    \"\"\"\n",
        "    \n",
        "    beam = [(input_seq,0)]\n",
        "    \n",
        "    for i in range(max_len):\n",
        "        candidates = []\n",
        "        candidates_proba = []\n",
        "        for snt, snt_proba in beam:\n",
        "            if snt[-1] == end_token:\n",
        "              candidates.append(snt)\n",
        "              candidates_proba.append(snt_proba)\n",
        "            else:    \n",
        "                proba = lm.infer(snt[-2],snt[-1], tau)\n",
        "                best_k = proba.argsort()[::-1][:k]               \n",
        "            \n",
        "                candidates.extend([snt+[int(element)] for element in best_k])\n",
        "                candidates_proba.extend([snt_proba + el for el in np.log(proba[best_k])])\n",
        "                \n",
        "        beam = []\n",
        "        for i in np.argsort(candidates_proba)[::-1][:k]:\n",
        "          beam.append((candidates[i], candidates_proba[i]))\n",
        "    return beam\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ftWXpwM2WBr",
        "colab_type": "code",
        "outputId": "320bb7d6-0abf-48a0-84f1-b395f53dc66d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        }
      },
      "source": [
        "input1 = 'horse '\n",
        "input1 = bpe.transform([input1])[0]\n",
        "result = beam_search(input1, lm, max_len=10, k=10, tau=0.1)\n",
        "# TODO print decoded generated strings and their probabilities\n",
        "for i in range(10):\n",
        "  print(bpe.decode(result[i][0]), result[i][1])"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "horse and the an -1.0048334157699486\n",
            "horse the and th -2.151178622063114\n",
            "horse and the th -2.1511786220631146\n",
            "horse and the sa -3.333043490162556\n",
            "horse and the so -3.550846727657047\n",
            "horse said the a -3.586426454965451\n",
            "horse the the an -3.776751794277742\n",
            "horse and the sh -4.021718350853669\n",
            "horse she and th -4.022227530008814\n",
            "horse so the and -4.038659205655186\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h8lSqaI2WBw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "64f3ff07-fb3c-46ed-9729-57518093c960"
      },
      "source": [
        "input1 = 'her'\n",
        "input1 = bpe.transform([input1])[0]\n",
        "result = beam_search(input1, lm, max_len=10, k=10, tau=0.1)\n",
        "# TODO print decoded generated strings and their probabilities\n",
        "for i in range(10):\n",
        "  print(bpe.decode(result[i][0]), result[i][1])"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "her the and t -0.8758370811243786\n",
            "her and the a -1.7326744147414819\n",
            "her the the a -2.501383655829784\n",
            "her and the t -2.8790462185438708\n",
            "her and the s -3.138039438949162\n",
            "her the said  -3.4420508801429968\n",
            "her the the t -3.6477554596321724\n",
            "her the the s -3.906748680037464\n",
            "her the so th -3.9096885738256137\n",
            "her the she a -4.372432563775484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM1ejoTt2WB0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "56971019-005f-4d48-ff5a-78e88d6827a8"
      },
      "source": [
        "input1 = 'what'\n",
        "input1 = bpe.transform([input1])[0]\n",
        "result = beam_search(input1, lm, max_len=10, k=10, tau=1)\n",
        "# TODO print decoded generated strings and their probabilities\n",
        "for i in range(10):\n",
        "  print(bpe.decode(result[i][0]), result[i][1])"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what of the th -9.202428511754622\n",
            "what the and t -9.273372192252266\n",
            "what the the a -9.55376061435879\n",
            "what of the an -9.559002325499288\n",
            "what the ther  -9.65141907898674\n",
            "what the the t -9.668397794739029\n",
            "what the the s -9.694297116779557\n",
            "what the and a -9.702632755988263\n",
            "what and the a -9.722736598721838\n",
            "what and the t -9.837373779102077\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbjFAicj2WB4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "f677d9be-5db6-49bb-aef9-cfdb176d48af"
      },
      "source": [
        "input1 = 'gun '\n",
        "input1 = bpe.transform([input1])[0]\n",
        "result = beam_search(input1, lm, max_len=10, k=10, tau=0.1)\n",
        "# TODO print decoded generated strings and their probabilities\n",
        "for i in range(10):\n",
        "  print(bpe.decode(result[i][0]), result[i][1])"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gun the and th -0.5170414482503506\n",
            "gun the the an -2.142614620464978\n",
            "gun the said t -3.0986610849550758\n",
            "gun the the th -3.2889598267581444\n",
            "gun the so the -3.550866545509102\n",
            "gun the she an -4.013663528410678\n",
            "gun the saing  -4.332098099824834\n",
            "gun the the sa -4.470824694857585\n",
            "gun the was an -4.642094941283447\n",
            "gun the the so -4.688627932352077\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}