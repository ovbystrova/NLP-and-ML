{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_assignment_5.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMGDBbGSho8x",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5eXBekihyDo",
        "colab_type": "text"
      },
      "source": [
        "Build CNN model for sentiment analysis (binary classification) of IMDB Reviews (https://www.kaggle.com/utathya/imdb-review-dataset). You can use data with label=\"unsup\" for pretraining of embeddings. Here you are forbidden to use test dataset for pretraining of embeddings.\n",
        "Your quality metric is accuracy score on test dataset. Look at \"type\" column for train/test split.\n",
        "You can use pretrained embeddings from external sources.\n",
        "You have to provide data for trials with different hyperparameter values.\n",
        "\n",
        "You have to beat following baselines:\n",
        "[3 points] acc = 0.75\n",
        "[5 points] acc = 0.8\n",
        "[8 points] acc = 0.9\n",
        "\n",
        "[2 points] for using unsupervised data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SKbq3nowr4fy",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "idd = '1smuY3sJJ6wcL28i0QcBSlnEsimB5holu'\n",
        "downloaded_ = drive.CreateFile({'id':idd}) \n",
        "downloaded_.GetContentFile('imdb_master.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ya8KscvDr5BQ",
        "outputId": "837d8933-bfbb-4af9-e4fc-ac5ed4ada420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.symbols import ORTH\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch\n",
        "from torchtext.data import Field, LabelField, BucketIterator, TabularDataset, Iterator, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "spacy_en = spacy.load('en')\n",
        "spacy_en.tokenizer.add_special_case(\"don't\", [{ORTH: \"do\"}, {ORTH: \"not\"}])\n",
        "spacy_en.tokenizer.add_special_case(\"didn't\", [{ORTH: \"did\"}, {ORTH: \"not\"}]) #adding special case so that tokenizer(\"\"\"don't\"\"\") != 'do'"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU-22kO4PNq5",
        "colab_type": "text"
      },
      "source": [
        "#0. Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR0ThTY8ufuI",
        "colab_type": "code",
        "outputId": "94b32dd0-2686-4400-b0a4-5e35b465285e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df = pd.read_csv('imdb_master.csv', sep=',', encoding= 'latin-1',  index_col=0)\n",
        "df = df.drop(columns=['file'])\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test</td>\n",
              "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                             review label\n",
              "0  test  Once again Mr. Costner has dragged out a movie...   neg\n",
              "1  test  This is an example of why the majority of acti...   neg\n",
              "2  test  First of all I hate those moronic rappers, who...   neg\n",
              "3  test  Not even the Beatles could write songs everyon...   neg\n",
              "4  test  Brass pictures (movies is not a fitting word f...   neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTC8Bl50aZ5E",
        "colab_type": "code",
        "outputId": "4188b8f7-b9a0-41ef-b15b-414bf86e5c2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Let's separate 'unsup' elements for now, but we will use them later\n",
        "mask = df['label'] == 'unsup'\n",
        "df_unsup = df[mask]\n",
        "df = df[~mask]\n",
        "len(df_unsup), len(df)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 50000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pa1jFy_a9bF",
        "colab_type": "code",
        "outputId": "37ce2643-aaaa-400c-e4c0-bc8a706fc248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#making sure that we don't have 'unsup' lables in test\n",
        "mask = df_unsup['type'] == 'test'\n",
        "len(df_unsup[mask])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUf41SV-cndV",
        "colab_type": "code",
        "outputId": "7e90e4e1-3281-4809-9786-a8796cfeeaa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#now we split our labled data to train and test\n",
        "mask = df['type'] == 'train'\n",
        "df_train = df[mask]\n",
        "df_test = df[~mask]\n",
        "len(df_train), len(df_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKBWdDUEXPlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.to_csv(\"dataset_train.csv\", index=False)\n",
        "df_test.to_csv(\"dataset_test.csv\", index=False)\n",
        "df_unsup.to_csv(\"dataset_unsup.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-PecH5rPxSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(text):\n",
        "    return [tok.lemma_ for tok in spacy_en.tokenizer(text) if tok.text.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhv5hIthSMdG",
        "colab_type": "code",
        "outputId": "07147662-782e-4307-af6a-48285ce190f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "classes={'neg': 0, 'pos': 1}\n",
        "\n",
        "REVIEW = Field(sequential=True, include_lengths=False, batch_first=True, tokenize=tokenizer, pad_first=True, lower=True, eos_token='<eos>',\n",
        "                    stop_words=nltk.corpus.stopwords.words('english')) \n",
        "LABEL = LabelField(dtype=torch.int64, use_vocab=True, preprocessing=lambda x: classes[x])\n",
        "\n",
        "train = TabularDataset('dataset_train.csv', \n",
        "                                format='csv', fields=[(None,None),('review', REVIEW),('label', LABEL)], \n",
        "                                skip_header=True)\n",
        "\n",
        "test = TabularDataset('dataset_test.csv', \n",
        "                                format='csv', fields=[(None,None),('review', REVIEW),('label', LABEL)], \n",
        "                                skip_header=True)\n",
        "\n",
        "dataset_unsup = TabularDataset('dataset_unsup.csv', \n",
        "                                format='csv', fields=[(None,None),('review', REVIEW), (None, None)], \n",
        "                                skip_header=True)\n",
        "\n",
        "REVIEW.build_vocab(train, dataset_unsup, min_freq=5, vectors=\"glove.6B.100d\") #we use 'unsup' data to build vocab/emb, but not test data\n",
        "LABEL.build_vocab(train, dataset_unsup)\n",
        "vocab = REVIEW.vocab"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                           \n",
            "100%|█████████▉| 399792/400000 [00:13<00:00, 29203.49it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEwgE_PyFBdC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All ready-to-use embeddings in torchtext\n",
        "#['charngram.100d', 'fasttext.en.300d', 'fasttext.simple.300d', 'glove.42B.300d', 'glove.840B.300d', 'glove.twitter.27B.25d', 'glove.twitter.27B.50d', 'glove.twitter.27B.100d', 'glove.twitter.27B.200d', 'glove.6B.50d', 'glove.6B.100d', 'glove.6B.200d', 'glove.6B.300d']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVN99RXXj1-v",
        "colab_type": "code",
        "outputId": "23ee919c-7375-46ce-9239-1e29d94141dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print('Vocab size:', len(REVIEW.vocab.itos))\n",
        "REVIEW.vocab.itos[:10]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 37105\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '<eos>',\n",
              " 'movie',\n",
              " 'film',\n",
              " '-pron-',\n",
              " 'much',\n",
              " 'one',\n",
              " 'good',\n",
              " 'see']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRXenE3tmOkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, valid = train.split(0.8, stratified=True, random_state=np.random.seed(SEED))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXotmgW4ydqk",
        "colab_type": "code",
        "outputId": "4e717c18-1e49-498a-faff-32112fa5fb91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(train[0].review)\n",
        "print(train[0].label)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['look', 'nothing', 'spectacularly', 'offensive', 'film', '-pron-', 'bore', '-pron-', 'typical', 'rom', 'com', 'end', 'see', 'come', '-pron-', 'see', 'much', 'trailer', 'key', 'difference', 'classic', 'rom', 'coms', 'tackle', 'story', 'wit', 'lack', 'pretension', 'movie', 'pretension', 'really', 'sense', 'movement', 'feel', 'though', 'get', 'walk', 'away', 'moment', 'production', 'movie', 'also', 'feel', 'debut', 'movie', 'make', 'fifteen', 'year', 'ago', '-pron-', 'recommend', 'watch', 'classic', 'movie', 'like', 'harry', 'met', 'sally', 'instead', 'shallow', 'imitation', 'oh', 'one', 'big', 'problem', 'chemistry', '-pron-', 'use', 'see', 'michael', 'look', 'cute', 'vaughn', 'alias', '-pron-', 'go', 'seriously', 'disappoint', 'way', '-pron-', 'make', 'look']\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DualFUVmWXZ",
        "colab_type": "text"
      },
      "source": [
        "# 1. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT7KYrWtmYaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, kernels, dropout):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.embedding.weight.data.copy_(vocab.vectors)        \n",
        "        self.convs = nn.ModuleList([nn.Conv1d(embed_size, hidden_size, k, padding=5) for k in kernels])\n",
        "        self.dropout = nn.Dropout(dropout)        \n",
        "        self.fc = nn.Linear(hidden_size * len(kernels), 2)\n",
        "        self.batch_norm = nn.BatchNorm1d(hidden_size)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.transpose(1,2)\n",
        "        \n",
        "        concatenated = []\n",
        "        for conv in self.convs:\n",
        "            z = conv(x)\n",
        "            z = self.batch_norm(z)\n",
        "            z = F.relu(z)\n",
        "            z = F.max_pool1d(z, kernel_size=z.size(2)).squeeze(2)\n",
        "            concatenated.append(z)\n",
        "            \n",
        "        x = torch.cat(concatenated, 1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pADiy0nFeQHX",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparams "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrW8tlieeTTe",
        "colab_type": "text"
      },
      "source": [
        "Попробуем руками посмотреть/подобрать гиперпараметры. Для этого создадим несколько моделей с разными наборами гиперпараметров и выберем ту, у которой лосс после двух эпох наименьший."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-QM6xuXmmAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(batch_size, hidden_size, kernels, dropout):\n",
        "    torch.cuda.empty_cache()    \n",
        "\n",
        "    model = MyModel(len(REVIEW.vocab.itos),\n",
        "                    embed_size=100,\n",
        "                    hidden_size=hidden_size,\n",
        "                    kernels=kernels,\n",
        "                    dropout = dropout\n",
        "                )\n",
        "\n",
        "    train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "        (train, valid, test),\n",
        "        batch_sizes=(batch_size, batch_size, batch_size),\n",
        "        shuffle=True,\n",
        "        sort_key=lambda x: len(x.review),\n",
        "    )\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True, cooldown=5)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    return model, train_iterator, valid_iterator, test_iterator, optimizer, scheduler, criterion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgNW1X-btpe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_cnn(model, train_iterator, valid_iterator, criterion, device, scheduler, n_epochs=20):\n",
        "    \n",
        "    history = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = []\n",
        "        train_acc = []\n",
        "        model.train()\n",
        "\n",
        "        for item in tqdm(train_iterator):\n",
        "            x = item.review\n",
        "            y = item.label\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(x)\n",
        "            loss = criterion(preds, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.data.detach().item())\n",
        "            train_acc.append(accuracy_score(y, np.argmax(preds.data.detach(), axis=1)))\n",
        "\n",
        "        train_loss = np.mean(train_loss)\n",
        "        train_acc = np.mean(train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = []\n",
        "        val_acc = []\n",
        "        with torch.no_grad():\n",
        "            for item in valid_iterator:\n",
        "                x = item.review\n",
        "                y = item.label\n",
        "                optimizer.zero_grad()\n",
        "                preds = model(x)\n",
        "                loss = criterion(preds, y)\n",
        "                val_loss.append(loss.data.detach().item())\n",
        "                val_acc.append(accuracy_score(y, torch.argmax(preds, dim=1)))\n",
        "        val_loss = np.mean(val_loss)\n",
        "        val_acc = np.mean(val_acc)   \n",
        "\n",
        "        scheduler.step(val_loss)    \n",
        "\n",
        "        print()\n",
        "        print('Epoch: {}; Train loss: {:.3f}; Train accuracy: {:.3f}; Val loss: {:.3f}; Val accuracy: {:.3f}'.format(\n",
        "            epoch, train_loss, train_acc, val_loss, val_acc\n",
        "        ))        \n",
        "        \n",
        "        history.append({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': train_loss,\n",
        "            'train_acc': train_acc,\n",
        "            'val_loss': val_loss,\n",
        "            'val_acc' : val_acc\n",
        "        })\n",
        "\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBtlmhz1hTKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_tqdm():\n",
        "    for instance in list(tqdm._instances): \n",
        "        tqdm._decr_instances(instance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVm1hW4fedT5",
        "colab_type": "text"
      },
      "source": [
        "Пойдем по жадному пути. Сначала выберем kernels, затем batch_size, затем hidden_state. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHsXuDu5euaZ",
        "colab_type": "code",
        "outputId": "bb36d2a2-c624-418c-9441-6328cce92801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        }
      },
      "source": [
        "#kernels = [2,3,4,5]\n",
        "clean_tqdm()\n",
        "model, train_iterator, valid_iterator, test_iterator, optimizer, scheduler, criterion = create_model(32, 128, [2,3,4,5], 0.1)\n",
        "history = train_cnn(model, train_iterator, valid_iterator,\n",
        "          criterion, scheduler=scheduler, device='cpu', n_epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 625/625 [05:21<00:00,  1.84it/s]\n",
            "  0%|          | 0/625 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0; Train loss: 0.499; Train accuracy: 0.789; Val loss: 0.367; Val accuracy: 0.838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [05:17<00:00,  2.02it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1; Train loss: 0.262; Train accuracy: 0.893; Val loss: 0.296; Val accuracy: 0.876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW6BJYRle1zL",
        "colab_type": "code",
        "outputId": "97918f10-2ce6-464a-ea15-3e7ca66cf434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "#kernels = [2,3]\n",
        "clean_tqdm()\n",
        "model, train_iterator, valid_iterator, test_iterator, optimizer, scheduler, criterion = create_model(32, 128, [2,3], 0.1)\n",
        "history = train_cnn(model, train_iterator, valid_iterator,\n",
        "          criterion, scheduler=scheduler,  device='cpu', n_epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [02:38<00:00,  3.79it/s]\n",
            "  0%|          | 0/625 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0; Train loss: 0.485; Train accuracy: 0.780; Val loss: 0.351; Val accuracy: 0.846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [02:36<00:00,  4.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1; Train loss: 0.285; Train accuracy: 0.882; Val loss: 0.295; Val accuracy: 0.879\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9IvbumAiJiS",
        "colab_type": "text"
      },
      "source": [
        "В принципе, loss не отличается почти, но вторая модель обучается в 2 раза быстрее => Будем использовать ее."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV1FrfRyfp1u",
        "colab_type": "code",
        "outputId": "e8aaf4d5-b262-4c79-afe3-0311c1d0a3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "# now we check batch_size = 64\n",
        "clean_tqdm()\n",
        "model, train_iterator, valid_iterator, test_iterator, optimizer, scheduler, criterion = create_model(64, 128, [2,3], 0.1)\n",
        "history = train_cnn(model, train_iterator, valid_iterator,\n",
        "          criterion, scheduler=scheduler, device='cpu', n_epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:44<00:00,  2.46it/s]\n",
            "  0%|          | 0/313 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0; Train loss: 0.541; Train accuracy: 0.755; Val loss: 0.331; Val accuracy: 0.859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [02:39<00:00,  1.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1; Train loss: 0.297; Train accuracy: 0.873; Val loss: 0.309; Val accuracy: 0.873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du5r1vmbiS5X",
        "colab_type": "text"
      },
      "source": [
        "Тут лучше себя показала модель с batch_size 32. Будем использовать ее."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifayvEf4f8YM",
        "colab_type": "code",
        "outputId": "79004c59-cff6-4db9-f5c8-3f41b83bf6bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "#hidden_size = 64\n",
        "clean_tqdm()\n",
        "model, train_iterator, valid_iterator, test_iterator, optimizer, scheduler, criterion = create_model(32, 64, [2,3], 0.1)\n",
        "history = train_cnn(model, train_iterator, valid_iterator,\n",
        "          criterion, scheduler=scheduler, device='cpu', n_epochs=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [01:43<00:00,  5.83it/s]\n",
            "  0%|          | 1/625 [00:00<01:46,  5.84it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0; Train loss: 0.477; Train accuracy: 0.775; Val loss: 0.380; Val accuracy: 0.828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [01:41<00:00,  6.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1; Train loss: 0.300; Train accuracy: 0.876; Val loss: 0.302; Val accuracy: 0.870\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq4BaA8xiZUm",
        "colab_type": "text"
      },
      "source": [
        "Берем hidden_size = 64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHKUJwq3gK3q",
        "colab_type": "text"
      },
      "source": [
        "Итого, лучшая модель будет такая (я запустила все ячейки выше пару раз, потом уже пропускала этот этап, чтобы не тратить время, сразу брала данные параметры): \n",
        "\n",
        "*   batch_size: 32\n",
        "*   hidden_size: 64\n",
        "*   kernels: [2,3]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB1D0G2Wgq8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Увеличила dropout т.к. модель переобучалась жестко.\n",
        "model , train_iterator, valid_iterator, test_iterator, optimizer, scheduler, criterion = create_model(32, 64, [2,3], 0.4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_zhqf1GnA9I",
        "colab_type": "code",
        "outputId": "cb5d5c94-b12d-49d5-f76c-b25b613a9451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (embedding): Embedding(37105, 100)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv1d(100, 64, kernel_size=(2,), stride=(1,), padding=(5,))\n",
              "    (1): Conv1d(100, 64, kernel_size=(3,), stride=(1,), padding=(5,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.4, inplace=False)\n",
              "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
              "  (batch_norm): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBt5Bt4rtkZM",
        "colab_type": "text"
      },
      "source": [
        "# 3. Training and evaluating our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqTrx2We0VT1",
        "colab_type": "code",
        "outputId": "ea5ff22e-027a-49d3-8f80-228cf79907b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "clean_tqdm()\n",
        "history = train_cnn(model, train_iterator, valid_iterator,\n",
        "          criterion, scheduler=scheduler, device='cpu', n_epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [01:41<00:00,  5.98it/s]\n",
            "  0%|          | 1/625 [00:00<01:48,  5.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0; Train loss: 0.613; Train accuracy: 0.715; Val loss: 0.387; Val accuracy: 0.826\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [01:40<00:00,  6.23it/s]\n",
            "  0%|          | 0/625 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1; Train loss: 0.373; Train accuracy: 0.837; Val loss: 0.328; Val accuracy: 0.860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [01:40<00:00,  6.88it/s]\n",
            "  0%|          | 1/625 [00:00<01:50,  5.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2; Train loss: 0.290; Train accuracy: 0.879; Val loss: 0.312; Val accuracy: 0.866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [01:40<00:00,  6.51it/s]\n",
            "  0%|          | 1/625 [00:00<01:49,  5.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3; Train loss: 0.218; Train accuracy: 0.914; Val loss: 0.313; Val accuracy: 0.866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 625/625 [01:39<00:00,  6.04it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 4; Train loss: 0.152; Train accuracy: 0.945; Val loss: 0.332; Val accuracy: 0.868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV5MsPR6cIVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, test_iterator):\n",
        "    model.eval()\n",
        "    test_acc = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for item in test_iterator:\n",
        "            x = item.review\n",
        "            y = item.label\n",
        "            preds = model(x)\n",
        "            hard_label_pred = torch.argmax(preds, dim=1)\n",
        "            test_acc.append(accuracy_score(y, hard_label_pred))\n",
        "    test_acc = np.mean(test_acc) \n",
        "    return test_acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P23Xizt7dL5Z",
        "colab_type": "code",
        "outputId": "4e440bd4-b4e7-4d45-fd05-449211ae8c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy = test_model(model, test_iterator)\n",
        "test_accuracy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.853300831202046"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ibCCPNljy9M",
        "colab_type": "text"
      },
      "source": [
        "#4. \"UNSUP\" data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LsFDB7zL4Um",
        "colab_type": "text"
      },
      "source": [
        "Идея простая: Берем две модели (TextBlob и SentimentIntensityAnalyzer), смотрим что они предсказывают для unsup данных. Если предсказания совпадают, берем, если нет - выкидываем. Но оказалось, что вторая модель большинство текстов определяет как нейтральные. Поэтому я взяла только TextBlob."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItSHrVUIL5bH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "3ea266b4-c03b-4a9e-94de-f8638725dcd4"
      },
      "source": [
        "!pip install vaderSentiment"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 25.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VavgUyrOL-XG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "23e71709-c1a6-48bd-8aff-454143c40c4b"
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YTGmPANL_Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SIA_fill(sentence):\n",
        "    sentence = ' '.join(tokenizer(sentence))\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    vs = analyzer.polarity_scores(sentence)\n",
        "    neg = vs['neg']\n",
        "    pos = vs['pos']\n",
        "    score = 'pos' if score > 0 else 'neg'\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iIYmcrBMBPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TextBlob_fill(sentence):\n",
        "    blob = TextBlob(sentence)\n",
        "    sentence = ' '.join(tokenizer(sentence))\n",
        "    score = blob.sentences[0].sentiment.polarity\n",
        "    score = 'pos' if score > 0 else 'neg'\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyc7_ZDjMDf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_unsup['label'] = df_unsup['review'].apply(TextBlob_fill) #TextBlob\n",
        "#df_unsup['label2'] = df_unsup['review'].apply(SIA_fill) #SentimentIntensityAnalyzer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbGeGD6IMm6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "0898d621-bebc-46ba-97f8-aefdbb9b00ed"
      },
      "source": [
        "mask = df_unsup['label'] == 'pos'\n",
        "print(len(df_unsup[mask]))\n",
        "print(len(df_unsup[~mask]))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26905\n",
            "23095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-akHpF0MpWV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "5ac7e44e-d947-42aa-8e13-f17fcf125d40"
      },
      "source": [
        "df_unsup.head()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50000</th>\n",
              "      <td>train</td>\n",
              "      <td>I admit, the great majority of films released ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50001</th>\n",
              "      <td>train</td>\n",
              "      <td>Take a low budget, inexperienced actors doubli...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50002</th>\n",
              "      <td>train</td>\n",
              "      <td>Everybody has seen 'Back To The Future,' right...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50003</th>\n",
              "      <td>train</td>\n",
              "      <td>Doris Day was an icon of beauty in singing and...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50004</th>\n",
              "      <td>train</td>\n",
              "      <td>After a series of silly, fun-loving movies, 19...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        type                                             review label\n",
              "50000  train  I admit, the great majority of films released ...   pos\n",
              "50001  train  Take a low budget, inexperienced actors doubli...   neg\n",
              "50002  train  Everybody has seen 'Back To The Future,' right...   pos\n",
              "50003  train  Doris Day was an icon of beauty in singing and...   pos\n",
              "50004  train  After a series of silly, fun-loving movies, 19...   neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg7vmQPLP4O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_unsup.to_csv(\"unsup_labels.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NT5Vz9HMzu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_unsup = TabularDataset('unsup_labels.csv', \n",
        "                                format='csv', fields=[(None, None), ('review', REVIEW), ('label', LABEL)], \n",
        "                                skip_header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4IHlXAYM2V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ds_concat  = train + dataset_unsup\n",
        "list_of_ex = [x for x in ds_concat]\n",
        "new_ds = Dataset(list_of_ex, [('review', REVIEW), ('label', LABEL)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFIjBq8mM4c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unsup_iterator = BucketIterator(\n",
        "        new_ds,\n",
        "        batch_size=32,\n",
        "        shuffle=False,\n",
        "        sort_key=lambda x: len(x.review),\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjJrtM2LNppd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7e01764-1292-4ac5-d17b-e2fc573a078c"
      },
      "source": [
        "#У меня упал колаб, поэтому тут уже просто загружаю веса (благо я их сохранила)\n",
        "model.load_state_dict(torch.load('model'))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPKTprcIM6is",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 740
        },
        "outputId": "0daaaa60-6c36-4468-a1e8-1fba89d83444"
      },
      "source": [
        "clean_tqdm()\n",
        "history = train_cnn(model, unsup_iterator, valid_iterator,\n",
        "          criterion, scheduler=scheduler, device='cpu', n_epochs=15)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|██████████| 2188/2188 [06:17<00:00,  5.80it/s]\n",
            "  0%|          | 1/2188 [00:00<04:43,  7.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0; Train loss: 0.511; Train accuracy: 0.733; Val loss: 0.532; Val accuracy: 0.762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2188/2188 [06:24<00:00,  5.69it/s]\n",
            "  0%|          | 1/2188 [00:00<04:50,  7.52it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 1; Train loss: 0.477; Train accuracy: 0.751; Val loss: 0.537; Val accuracy: 0.726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2188/2188 [06:28<00:00,  5.64it/s]\n",
            "  0%|          | 1/2188 [00:00<04:55,  7.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 2; Train loss: 0.435; Train accuracy: 0.779; Val loss: 0.561; Val accuracy: 0.711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2188/2188 [06:28<00:00,  5.63it/s]\n",
            "  0%|          | 1/2188 [00:00<04:39,  7.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 3; Train loss: 0.395; Train accuracy: 0.807; Val loss: 0.553; Val accuracy: 0.726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2188/2188 [06:26<00:00,  5.66it/s]\n",
            "  0%|          | 1/2188 [00:00<04:49,  7.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch     4: reducing learning rate of group 0 to 1.0000e-04.\n",
            "\n",
            "Epoch: 4; Train loss: 0.349; Train accuracy: 0.837; Val loss: 0.619; Val accuracy: 0.697\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2188/2188 [06:29<00:00,  5.62it/s]\n",
            "  0%|          | 1/2188 [00:00<04:32,  8.03it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 5; Train loss: 0.363; Train accuracy: 0.843; Val loss: 0.580; Val accuracy: 0.737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2188/2188 [06:28<00:00,  5.63it/s]\n",
            "  0%|          | 1/2188 [00:00<04:47,  7.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 6; Train loss: 0.338; Train accuracy: 0.853; Val loss: 0.584; Val accuracy: 0.737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 18%|█▊        | 399/2188 [01:12<05:45,  5.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-c4361f8d332d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclean_tqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = train_cnn(model, unsup_iterator, valid_iterator,\n\u001b[0;32m----> 3\u001b[0;31m           criterion, scheduler=scheduler, device='cpu', n_epochs=15)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-ce2a5b1953f1>\u001b[0m in \u001b[0;36mtrain_cnn\u001b[0;34m(model, train_iterator, valid_iterator, criterion, device, scheduler, n_epochs)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-d3fe959c9c78>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mconcatenated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIFnaaEqM8oT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "beae516f-9464-4531-e116-f76ee3d810bd"
      },
      "source": [
        "test_accuracy = test_model(model, test_iterator)\n",
        "test_accuracy"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6929747442455243"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyzbY3oudolz",
        "colab_type": "text"
      },
      "source": [
        "Как-то вообще не очень. Но лучший результат на тесте: 0.85!"
      ]
    }
  ]
}