{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Aspect_assignment_9.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mokaem4OdnJ1",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 9\n",
        "\n",
        "Use data from `https://github.com/thedenaas/hse_seminars/tree/master/2018/seminar_13/data.zip`  \n",
        "Implement model in pytorch from \"An Unsupervised Neural Attention Model for Aspect Extraction, He et al, 2017\", also desribed in seminar notes.  \n",
        "\n",
        "You can use sentence embeddings with attention **[7 points]**:  \n",
        "$z_s = \\sum_{i}^n \\alpha_i e_{w_i}, z_s \\in R^d$ sentence embedding  \n",
        "$\\alpha_i = softmax(d_i)$  attention weight for i-th token  \n",
        "$d_i = e_{w_i}^T M y_s$ attention with trainable matrix $M \\in R^{dxd}$  \n",
        "$y_s = \\frac 1 n \\sum_{i=1}^n e_{w_i}, y_s \\in R^d$ sentence context  \n",
        "$e_{w_i} \\in R^d$, token embedding of size d  \n",
        "$n$ - number of tokens in a sentence  \n",
        "\n",
        "**Or** just use sentence embedding as an average over word embeddings **[5 points]**:  \n",
        "$z_s = \\frac 1 n \\sum_{i=1}^n e_{w_i}, z_s \\in R^d$ sentence embedding  \n",
        "$e_{w_i} \\in R^d$, token embedding of size d  \n",
        "$n$ - number of tokens in a sentence  \n",
        " \n",
        "$p_t = softmax(W z_s + b), p_t \\in R^K$ topic weights for sentence $s$, with trainable matrix $W \\in R^{dxK}$ and bias vector $b \\in R^K$  \n",
        "$r_s = T^T p_t, r_s \\in R^d$ reconstructed sentence embedding as a weighted sum of topic embeddings   \n",
        "$T \\in R^{Kxd}$ trainable matrix of topic embeddings, K=number of topics\n",
        "\n",
        "\n",
        "**Training objective**:\n",
        "$$ J = \\sum_{s \\in D} \\sum_{i=1}^n max(0, 1-r_s^T z_s + r_s^T n_i) + \\lambda ||T^T T - I ||^2_F  $$\n",
        "where   \n",
        "$m$ random sentences are sampled as negative examples from dataset $D$ for each sentence $s$  \n",
        "$n_i = \\frac 1 n \\sum_{i=j}^n e_{w_j}$ average of word embeddings in the i-th sentence  \n",
        "$||T^T T - I ||_F$ regularizer, that enforces matrix $T$ to be orthogonal  \n",
        "$||A||^2_F = \\sum_{i=1}^N\\sum_{j=1}^M a_{ij}^2, A \\in R^{NxM}$ Frobenius norm\n",
        "\n",
        "\n",
        "**[3 points]** Compute topic coherence for at least for 3 different number of topics. Use 10 nearest words for each topic. It means you have to train one model for each number of topics. You can use code from seminar notes with word2vec similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IwUDMDqpz13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO Заменить texts[23] на что-то более разумное при выборе негативных экземпляров\n",
        "# TODO Заменить в TabularDataset, чтобы neg_{} зависило от NEG_SAMPLES\n",
        "# TODO Удалить пунктуацию"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-qmDndFbY1F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "bd11efbb-23de-4488-af9d-7c4cbf41fc0e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import nltk\n",
        "\n",
        "from torchtext.vocab import Vectors\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKAfiuLxbGFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "NEG_SAMPLES = 3  # number of negative samples\n",
        "random_state = 23\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKNWvW7zd2Is",
        "colab_type": "text"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqUNSQFBKhrp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "337a5465-adb1-4cc6-daa1-ba8e1447a90b"
      },
      "source": [
        "!wget -O data.zip https://github.com/thedenaas/hse_seminars/blob/master/2018/seminar_13/data.zip?raw=true\n",
        "!unzip '/content/data.zip'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-20 14:17:52--  https://github.com/thedenaas/hse_seminars/blob/master/2018/seminar_13/data.zip?raw=true\n",
            "Resolving github.com (github.com)... 13.229.188.59\n",
            "Connecting to github.com (github.com)|13.229.188.59|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/thedenaas/hse_seminars/raw/master/2018/seminar_13/data.zip [following]\n",
            "--2020-03-20 14:17:52--  https://github.com/thedenaas/hse_seminars/raw/master/2018/seminar_13/data.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2018/seminar_13/data.zip [following]\n",
            "--2020-03-20 14:17:53--  https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2018/seminar_13/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9927168 (9.5M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   9.47M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2020-03-20 14:17:54 (152 MB/s) - ‘data.zip’ saved [9927168/9927168]\n",
            "\n",
            "Archive:  /content/data.zip\n",
            "replace data.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa2LqXnxeFDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with open('/content/data.txt', 'r') as f:\n",
        "#     data = f.read().splitlines()\n",
        "\n",
        "with open('/content/data.txt', 'r') as f:\n",
        "    data = nltk.tokenize.sent_tokenize(f.read())\n",
        "\n",
        "with open('/content/stopwords.txt', 'r') as f:\n",
        "    stopwords = f.read().splitlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMiKbiGGfoik",
        "colab_type": "code",
        "outputId": "9e760cbc-fbeb-489c-bf82-c0bf210bd07d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print(len(data), data[0])\n",
        "print(len(stopwords), stopwords[0])"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "183400 Barclays' defiance of US fines has merit Barclays disgraced itself in many ways during the pre-financial crisis boom years.\n",
            "350 a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox4BJMR2kHy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/data.txt', 'r') as f:\n",
        "    data = nltk.tokenize.sent_tokenize(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV9X4G4kT5hm",
        "colab_type": "text"
      },
      "source": [
        "# Making DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwdWOnwveQcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_df(texts, neg_samples):\n",
        "    \"\"\"\n",
        "    Creating pandas DataFrame from texts and adding randomly chosen negative samples\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    df['text'] = texts\n",
        "\n",
        "    for i in range(1, neg_samples+1):\n",
        "        df['neg_{}'.format(i)] = [texts[ind] if ind != el else texts[23] for el, ind in enumerate(np.random.choice(np.arange(0,len(texts)), size=len(texts)))]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEE6p8yXe9m7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = create_df(data, neg_samples=NEG_SAMPLES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QuhOhXQfIys",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "aa861eab-e06d-4b1e-c819-c5dd75f7181d"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>neg_1</th>\n",
              "      <th>neg_2</th>\n",
              "      <th>neg_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barclays' defiance of US fines has merit Barcl...</td>\n",
              "      <td>Aides have yet to say whether he was speaking ...</td>\n",
              "      <td>Instead today NHS England announced it was not...</td>\n",
              "      <td>And part of the reason, according to CNBC’s Ji...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So it is tempting to think the bank, when aske...</td>\n",
              "      <td>The EU did run up backlog of €26bn (£20bn) in ...</td>\n",
              "      <td>“The developing, poorer countries are impacted...</td>\n",
              "      <td>(And when he does, well you can’t fault him fo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>That is not the view of the chief executive, J...</td>\n",
              "      <td>Nigel Farage and the other Ukip MEPs, as well ...</td>\n",
              "      <td>For her part, Swami Ambikananda Saraswati seem...</td>\n",
              "      <td>“We are now here with our crying four year old...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Barclays thinks the DoJ’s claims are “disconne...</td>\n",
              "      <td>And so an easy dichotomy presents itself.</td>\n",
              "      <td>Conor D’Arcy, a policy analyst at the Resoluti...</td>\n",
              "      <td>Footloose On paper, even now, the setup of thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>But actually, some grudging respect for Staley...</td>\n",
              "      <td>A documentary crew invited to film the recordi...</td>\n",
              "      <td>Bill Clinton is still somewhere on a bus in Oh...</td>\n",
              "      <td>“Maybe that’s it!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                              neg_3\n",
              "0  Barclays' defiance of US fines has merit Barcl...  ...  And part of the reason, according to CNBC’s Ji...\n",
              "1  So it is tempting to think the bank, when aske...  ...  (And when he does, well you can’t fault him fo...\n",
              "2  That is not the view of the chief executive, J...  ...  “We are now here with our crying four year old...\n",
              "3  Barclays thinks the DoJ’s claims are “disconne...  ...  Footloose On paper, even now, the setup of thi...\n",
              "4  But actually, some grudging respect for Staley...  ...                                  “Maybe that’s it!\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xZi1Yn0T-UD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "0dd6e9f9-8875-4d50-b44f-d7c84577056d"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>neg_1</th>\n",
              "      <th>neg_2</th>\n",
              "      <th>neg_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>183395</th>\n",
              "      <td>It feels as though Stone realised that some of...</td>\n",
              "      <td>Steven W Thrasher: Trump is better at whipping...</td>\n",
              "      <td>So, here you would think, is an open goal – a ...</td>\n",
              "      <td>The question is whether our top law enforcemen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183396</th>\n",
              "      <td>There are some fun elements, many involving Rh...</td>\n",
              "      <td>The tracks that really shine the most though a...</td>\n",
              "      <td>One man, bless his heart, all but leapt into t...</td>\n",
              "      <td>FGM is defined by the World Health Organisatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183397</th>\n",
              "      <td>I particularly enjoyed a scene in which O’Bria...</td>\n",
              "      <td>Having an eating disorder is extremely isolati...</td>\n",
              "      <td>Run-in 2 Apr Man City H 9 Apr Aston Villa A 17...</td>\n",
              "      <td>No Man’s Sky shares the film’s tranquil pace, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183398</th>\n",
              "      <td>His carnivorous snarl fills the immense screen...</td>\n",
              "      <td>He noted that often the party’s nominee did no...</td>\n",
              "      <td>The Oscars is on February 28.</td>\n",
              "      <td>Chelsea Clinton will attend a glitzy, star-stu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183399</th>\n",
              "      <td>There’s a playful visual flair to this moment ...</td>\n",
              "      <td>So help us to get a sense of the country as th...</td>\n",
              "      <td>I looked at TV pictures of a home match this m...</td>\n",
              "      <td>As the virus continues to spread since the fir...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  ...                                              neg_3\n",
              "183395  It feels as though Stone realised that some of...  ...  The question is whether our top law enforcemen...\n",
              "183396  There are some fun elements, many involving Rh...  ...  FGM is defined by the World Health Organisatio...\n",
              "183397  I particularly enjoyed a scene in which O’Bria...  ...  No Man’s Sky shares the film’s tranquil pace, ...\n",
              "183398  His carnivorous snarl fills the immense screen...  ...  Chelsea Clinton will attend a glitzy, star-stu...\n",
              "183399  There’s a playful visual flair to this moment ...  ...  As the virus continues to spread since the fir...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDbab41hoQzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('data.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07kqgnqzoOh5",
        "colab_type": "text"
      },
      "source": [
        "# TORCHTEXT and stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5JIpVVUvHgA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy \n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtGq1QulqO1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    return [tok.lemma_ for tok in spacy_en.tokenizer(text) if tok.text.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuQh6VfuaqzO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4276cbd3-7331-4451-eab8-cde7e651bd2c"
      },
      "source": [
        "# Using data to pretrain word-embeddings\n",
        "\n",
        "data_tokenized = list(df['text'].apply(lambda x: tokenize(x)))\n",
        "model = Word2Vec(data_tokenized, size=200, window=10, negative=5)  # building emb of size 200 (parameters from the paper)\n",
        "model_weights = torch.FloatTensor(model.wv.vectors)\n",
        "model.wv.save_word2vec_format('pretrained_embeddings')\n",
        "vectors = Vectors(name='pretrained_embeddings', cache='./')  # and saving the weights to build vocab later"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUwMzL7BqJBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext.data import Field, TabularDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcuDPIccohZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
        "\n",
        "TEXT = Field(sequential=True, \n",
        "             include_lengths=False, \n",
        "             batch_first=True, \n",
        "             tokenize=tokenize, \n",
        "             lower=True)\n",
        "\n",
        "RESULT = Field(sequential=True, \n",
        "             include_lengths=False, \n",
        "             batch_first=True, \n",
        "             tokenize=tokenize, \n",
        "             lower=True,\n",
        "             is_target=True)\n",
        "\n",
        "dataset = TabularDataset(\n",
        "           path=\"/content/data.csv\",\n",
        "           format='csv',\n",
        "           skip_header=True,\n",
        "           fields=[('text', RESULT),('neg_1', TEXT), ('neg_2', TEXT), ('neg_3', TEXT)])\n",
        "\n",
        "TEXT.build_vocab(dataset, min_freq=2, vectors=vectors,\n",
        "                   unk_init = torch.Tensor.normal_)\n",
        "\n",
        "RESULT.build_vocab(dataset, min_freq=2, vectors=vectors,\n",
        "                   unk_init = torch.Tensor.normal_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBiZPau_tq94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = TEXT.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WDBH_AFtI8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "52a1c71f-6443-427b-a465-9fe1dcc78263"
      },
      "source": [
        "print('Vocab size:', len(TEXT.vocab.itos))\n",
        "TEXT.vocab.itos[:10]"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 52932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', 'the', 'be', 'a', 'to', 'of', 'and', 'in', 'that']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LsY9Jr7zA1y",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwBbIppuzB7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer = Adam\n",
        "\n",
        "# learning rate 0.001 for 15 epochs and batch size of 50. \n",
        "# We set the number of negative samples per input sample m to 20,\n",
        "# λ to 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Wg8Gj_zCYa",
        "colab_type": "text"
      },
      "source": [
        "# Topic CoHerence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg9mNs1uzEza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}