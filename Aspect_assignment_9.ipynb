{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Aspect_assignment_9.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92a1d77b98de4c3b82efc0e005b724bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e92f2f17a8234662a23759b3c02fc4da",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7135bf419172456f95a0d6de2d5fd945",
              "IPY_MODEL_330bb89a2ba94dbb923ecd3f01f5a3d3"
            ]
          }
        },
        "e92f2f17a8234662a23759b3c02fc4da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7135bf419172456f95a0d6de2d5fd945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3acca2322a0a4c1090a8638bfacbbba3",
            "_dom_classes": [],
            "description": "epoch 0: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1834,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1834,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_baabd368226e4ceda82bb4a3f3a593b1"
          }
        },
        "330bb89a2ba94dbb923ecd3f01f5a3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_25a04fc1a1424a42bb3f709de2bb23b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1834/1834 [02:03&lt;00:00, 14.80it/s, loss=0.02506]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91195fdb9c3742ea9c477634421de74f"
          }
        },
        "3acca2322a0a4c1090a8638bfacbbba3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "baabd368226e4ceda82bb4a3f3a593b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "25a04fc1a1424a42bb3f709de2bb23b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91195fdb9c3742ea9c477634421de74f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3afeba473a544877bc24dbcc2b6e2b29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8190c6d6a438442d9b0b72a4c68383b7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_021b4bad7c9745cda52db3ea8ab09ac7",
              "IPY_MODEL_1e128dfc600b4b35990090824b88a23e"
            ]
          }
        },
        "8190c6d6a438442d9b0b72a4c68383b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "021b4bad7c9745cda52db3ea8ab09ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0c70f0e36734b1384ed3b3d03756ac2",
            "_dom_classes": [],
            "description": "epoch 1: 100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 1834,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1834,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_40b552b3d56943689022eb84ccf3c366"
          }
        },
        "1e128dfc600b4b35990090824b88a23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc1a696a09464904be8dad41c777e948",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1834/1834 [02:00&lt;00:00, 15.19it/s, loss=0.00006]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0b55ab96d57d44c5ac84fc059282114a"
          }
        },
        "a0c70f0e36734b1384ed3b3d03756ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "40b552b3d56943689022eb84ccf3c366": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc1a696a09464904be8dad41c777e948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0b55ab96d57d44c5ac84fc059282114a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd54751d2e1643029960d79834c2601d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_aede1b3c16164cb3bfaca2c7214142fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d26e5f496430424d8852f4acc1ced5d6",
              "IPY_MODEL_32c8efbc7b46433bb946fe9389e64541"
            ]
          }
        },
        "aede1b3c16164cb3bfaca2c7214142fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d26e5f496430424d8852f4acc1ced5d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_79d51232ab3e418e97d9e07ea1ac7d08",
            "_dom_classes": [],
            "description": "epoch 2:   3%",
            "_model_name": "IntProgressModel",
            "bar_style": "danger",
            "max": 1834,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 47,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_273f5e2fdaec4ba6a041136f61cba3c6"
          }
        },
        "32c8efbc7b46433bb946fe9389e64541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0ff1eeddd57344abb48f5b3ea5e6e759",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 47/1834 [00:19&lt;01:56, 15.40it/s, loss=0.00006]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_04c64944ad834bbda58e92335ed7a5cb"
          }
        },
        "79d51232ab3e418e97d9e07ea1ac7d08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "273f5e2fdaec4ba6a041136f61cba3c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ff1eeddd57344abb48f5b3ea5e6e759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "04c64944ad834bbda58e92335ed7a5cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mokaem4OdnJ1",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 9\n",
        "\n",
        "Use data from `https://github.com/thedenaas/hse_seminars/tree/master/2018/seminar_13/data.zip`  \n",
        "Implement model in pytorch from \"An Unsupervised Neural Attention Model for Aspect Extraction, He et al, 2017\", also desribed in seminar notes.  \n",
        "\n",
        "You can use sentence embeddings with attention **[7 points]**:  \n",
        "$z_s = \\sum_{i}^n \\alpha_i e_{w_i}, z_s \\in R^d$ sentence embedding  \n",
        "$\\alpha_i = softmax(d_i)$  attention weight for i-th token  \n",
        "$d_i = e_{w_i}^T M y_s$ attention with trainable matrix $M \\in R^{dxd}$  \n",
        "$y_s = \\frac 1 n \\sum_{i=1}^n e_{w_i}, y_s \\in R^d$ sentence context  \n",
        "$e_{w_i} \\in R^d$, token embedding of size d  \n",
        "$n$ - number of tokens in a sentence  \n",
        "\n",
        "**Or** just use sentence embedding as an average over word embeddings **[5 points]**:  \n",
        "$z_s = \\frac 1 n \\sum_{i=1}^n e_{w_i}, z_s \\in R^d$ sentence embedding  \n",
        "$e_{w_i} \\in R^d$, token embedding of size d  \n",
        "$n$ - number of tokens in a sentence  \n",
        " \n",
        "$p_t = softmax(W z_s + b), p_t \\in R^K$ topic weights for sentence $s$, with trainable matrix $W \\in R^{dxK}$ and bias vector $b \\in R^K$  \n",
        "$r_s = T^T p_t, r_s \\in R^d$ reconstructed sentence embedding as a weighted sum of topic embeddings   \n",
        "$T \\in R^{Kxd}$ trainable matrix of topic embeddings, K=number of topics\n",
        "\n",
        "\n",
        "**Training objective**:\n",
        "$$ J = \\sum_{s \\in D} \\sum_{i=1}^n max(0, 1-r_s^T z_s + r_s^T n_i) + \\lambda ||T^T T - I ||^2_F  $$\n",
        "where   \n",
        "$m$ random sentences are sampled as negative examples from dataset $D$ for each sentence $s$  \n",
        "$n_i = \\frac 1 n \\sum_{i=j}^n e_{w_j}$ average of word embeddings in the i-th sentence  \n",
        "$||T^T T - I ||_F$ regularizer, that enforces matrix $T$ to be orthogonal  \n",
        "$||A||^2_F = \\sum_{i=1}^N\\sum_{j=1}^M a_{ij}^2, A \\in R^{NxM}$ Frobenius norm\n",
        "\n",
        "\n",
        "**[3 points]** Compute topic coherence for at least for 3 different number of topics. Use 10 nearest words for each topic. It means you have to train one model for each number of topics. You can use code from seminar notes with word2vec similarity scores."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IwUDMDqpz13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO Заменить texts[23] на что-то более разумное при выборе негативных экземпляров\n",
        "# TODO Заменить в TabularDataset, чтобы neg_{} зависило от NEG_SAMPLES\n",
        "# TODO Сделать в модели так, чтобы neg не было фиксированным, а зависело от NEG_SAMPLES\n",
        "# TODO Определить и проверить структуру Лосса."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-qmDndFbY1F",
        "colab_type": "code",
        "outputId": "ed27ee6b-cde4-4a36-9624-6761e895fbcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "import spacy \n",
        "\n",
        "import torch\n",
        "from torchtext.data import Field, TabularDataset, BucketIterator\n",
        "from torchtext.vocab import Vectors\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "nltk.download('punkt')\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKAfiuLxbGFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "NEG_SAMPLES = 3  # number of negative samples\n",
        "random_state = 23\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKNWvW7zd2Is",
        "colab_type": "text"
      },
      "source": [
        "# DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqUNSQFBKhrp",
        "colab_type": "code",
        "outputId": "c35b2ace-994f-422b-bb72-c3a89545a60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "!wget -O data.zip https://github.com/thedenaas/hse_seminars/blob/master/2018/seminar_13/data.zip?raw=true\n",
        "!unzip '/content/data.zip'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-22 10:48:11--  https://github.com/thedenaas/hse_seminars/blob/master/2018/seminar_13/data.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/thedenaas/hse_seminars/raw/master/2018/seminar_13/data.zip [following]\n",
            "--2020-03-22 10:48:11--  https://github.com/thedenaas/hse_seminars/raw/master/2018/seminar_13/data.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2018/seminar_13/data.zip [following]\n",
            "--2020-03-22 10:48:12--  https://raw.githubusercontent.com/thedenaas/hse_seminars/master/2018/seminar_13/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9927168 (9.5M) [application/zip]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]   9.47M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-03-22 10:48:12 (78.4 MB/s) - ‘data.zip’ saved [9927168/9927168]\n",
            "\n",
            "Archive:  /content/data.zip\n",
            "  inflating: data.txt                \n",
            "  inflating: stopwords.txt           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa2LqXnxeFDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/data.txt', 'r') as f:\n",
        "    data = nltk.tokenize.sent_tokenize(f.read())\n",
        "\n",
        "with open('/content/stopwords.txt', 'r') as f:\n",
        "    stopwords = f.read().splitlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMiKbiGGfoik",
        "colab_type": "code",
        "outputId": "21c8c5eb-6c24-4070-9ad4-db82c7006e54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(len(data), data[0])\n",
        "print(len(stopwords), stopwords[0])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "183400 Barclays' defiance of US fines has merit Barclays disgraced itself in many ways during the pre-financial crisis boom years.\n",
            "350 a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV9X4G4kT5hm",
        "colab_type": "text"
      },
      "source": [
        "# Making DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwdWOnwveQcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_df(texts, neg_samples):\n",
        "    \"\"\"\n",
        "    Creating pandas DataFrame from texts and adding randomly chosen negative samples\n",
        "    \"\"\"\n",
        "    df = pd.DataFrame()\n",
        "    df['text'] = texts\n",
        "\n",
        "    for i in range(1, neg_samples+1):\n",
        "        df['neg_{}'.format(i)] = [texts[ind] if ind != el else texts[23] for el, ind in enumerate(np.random.choice(np.arange(0,len(texts)), size=len(texts)))]\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEE6p8yXe9m7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = create_df(data, neg_samples=NEG_SAMPLES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QuhOhXQfIys",
        "colab_type": "code",
        "outputId": "49aef19d-266a-41fe-8103-5868a5e6aaba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>neg_1</th>\n",
              "      <th>neg_2</th>\n",
              "      <th>neg_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Barclays' defiance of US fines has merit Barcl...</td>\n",
              "      <td>We are also changing the process for new comme...</td>\n",
              "      <td>When are football clubs going to start this ki...</td>\n",
              "      <td>The whole thing stinks to high heaven.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>So it is tempting to think the bank, when aske...</td>\n",
              "      <td>Instead, like most, I found I was more British...</td>\n",
              "      <td>Jess Bradley of Action for Trans Health, a cam...</td>\n",
              "      <td>“We’ve received your loan inquiry.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>That is not the view of the chief executive, J...</td>\n",
              "      <td>The decision by the chancellor, Philip Hammond...</td>\n",
              "      <td>No decision has been taken on the cost to pass...</td>\n",
              "      <td>“Lock her up, lock her up,” chanted the crowd,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Barclays thinks the DoJ’s claims are “disconne...</td>\n",
              "      <td>“My focus is on winning the largest state in o...</td>\n",
              "      <td>Very well deserved and a demonstration that yo...</td>\n",
              "      <td>“We can’t spread existing funding across Austr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>But actually, some grudging respect for Staley...</td>\n",
              "      <td>But there are also movies covered where film m...</td>\n",
              "      <td>During that nervy, scratchy period Palace were...</td>\n",
              "      <td>The current debate over diversity in films, he...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                              neg_3\n",
              "0  Barclays' defiance of US fines has merit Barcl...  ...             The whole thing stinks to high heaven.\n",
              "1  So it is tempting to think the bank, when aske...  ...                 “We’ve received your loan inquiry.\n",
              "2  That is not the view of the chief executive, J...  ...  “Lock her up, lock her up,” chanted the crowd,...\n",
              "3  Barclays thinks the DoJ’s claims are “disconne...  ...  “We can’t spread existing funding across Austr...\n",
              "4  But actually, some grudging respect for Staley...  ...  The current debate over diversity in films, he...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xZi1Yn0T-UD",
        "colab_type": "code",
        "outputId": "3384e71c-ef82-4897-f29e-c7265fd6dae6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>neg_1</th>\n",
              "      <th>neg_2</th>\n",
              "      <th>neg_3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>183395</th>\n",
              "      <td>It feels as though Stone realised that some of...</td>\n",
              "      <td>To miss out by one goal … to see a team playin...</td>\n",
              "      <td>The contrast with 2014’s Scottish referendum i...</td>\n",
              "      <td>“What do we want?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183396</th>\n",
              "      <td>There are some fun elements, many involving Rh...</td>\n",
              "      <td>Alison Macfarlane, a professor of perinatal he...</td>\n",
              "      <td>I can pretty much remember where each and ever...</td>\n",
              "      <td>Most say they don’t deliberately withhold bad ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183397</th>\n",
              "      <td>I particularly enjoyed a scene in which O’Bria...</td>\n",
              "      <td>Sid Lowe has the latest ...</td>\n",
              "      <td>I think Dan Jarvis is a really good guy.</td>\n",
              "      <td>Thus begat Cinerama, an initially successful e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183398</th>\n",
              "      <td>His carnivorous snarl fills the immense screen...</td>\n",
              "      <td>O’Malley has the option, if he wants to narrow...</td>\n",
              "      <td>They were almost entirely ignored.</td>\n",
              "      <td>“There’s going to be a tremendous problem” if ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183399</th>\n",
              "      <td>There’s a playful visual flair to this moment ...</td>\n",
              "      <td>My rule of thumb, which I continue to follow, ...</td>\n",
              "      <td>He also worked for the Rolling Stones on their...</td>\n",
              "      <td>Certainly Republican women angrily withdrew th...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  ...                                              neg_3\n",
              "183395  It feels as though Stone realised that some of...  ...                                  “What do we want?\n",
              "183396  There are some fun elements, many involving Rh...  ...  Most say they don’t deliberately withhold bad ...\n",
              "183397  I particularly enjoyed a scene in which O’Bria...  ...  Thus begat Cinerama, an initially successful e...\n",
              "183398  His carnivorous snarl fills the immense screen...  ...  “There’s going to be a tremendous problem” if ...\n",
              "183399  There’s a playful visual flair to this moment ...  ...  Certainly Republican women angrily withdrew th...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDbab41hoQzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('data.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07kqgnqzoOh5",
        "colab_type": "text"
      },
      "source": [
        "# TORCHTEXT and stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtGq1QulqO1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(text):\n",
        "    return [tok.lemma_ for tok in spacy_en.tokenizer(text) if tok.text.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuQh6VfuaqzO",
        "colab_type": "code",
        "outputId": "ea1e6064-6788-4012-f747-dc9704c9273c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# Using data to pretrain word-embeddings\n",
        "\n",
        "data_tokenized = list(df['text'].apply(lambda x: tokenize(x)))\n",
        "model = Word2Vec(data_tokenized, size=200, window=10, negative=5)  # building emb of size 200 (parameters from the paper)\n",
        "model_weights = torch.FloatTensor(model.wv.vectors)\n",
        "model.wv.save_word2vec_format('pretrained_embeddings')\n",
        "vectors = Vectors(name='pretrained_embeddings', cache='./')  # and saving the weights to build vocab later"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "  0%|          | 0/24240 [00:00<?, ?it/s]Skipping token b'24240' with 1-dimensional vector [b'200']; likely a header\n",
            "100%|█████████▉| 24203/24240 [00:01<00:00, 14941.65it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcuDPIccohZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://mlexplained.com/2018/02/08/a-comprehensive-tutorial-to-torchtext/\n",
        "\n",
        "TEXT = Field(sequential=True, \n",
        "             include_lengths=False, \n",
        "             batch_first=True, \n",
        "             tokenize=tokenize, \n",
        "             lower=True, \n",
        "             stop_words=stopwords)\n",
        "\n",
        "# RESULT = Field(sequential=True, \n",
        "#              include_lengths=False, \n",
        "#              batch_first=True, \n",
        "#              tokenize=tokenize, \n",
        "#              lower=True,\n",
        "#              stop_words=stopwords)\n",
        "\n",
        "dataset = TabularDataset(\n",
        "           path=\"/content/data.csv\",\n",
        "           format='csv',\n",
        "           skip_header=True,\n",
        "           fields=[('text', TEXT),('neg_1', TEXT), ('neg_2', TEXT), ('neg_3', TEXT)])\n",
        "\n",
        "TEXT.build_vocab(dataset, min_freq=2, vectors=vectors,\n",
        "                   unk_init = torch.Tensor.normal_)\n",
        "\n",
        "RESULT.build_vocab(dataset, min_freq=2, vectors=vectors,\n",
        "                   unk_init = torch.Tensor.normal_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBiZPau_tq94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = TEXT.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WDBH_AFtI8y",
        "colab_type": "code",
        "outputId": "7674a667-e411-4d73-dacc-5379a6c33412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print('Vocab size:', len(TEXT.vocab.itos))\n",
        "TEXT.vocab.itos[:10]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 55879\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>',\n",
              " '<pad>',\n",
              " '-pron-',\n",
              " 'i',\n",
              " 'trump',\n",
              " 'people',\n",
              " 'go',\n",
              " 'get',\n",
              " 'time',\n",
              " 'take']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXwi8Ip5CQQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        },
        "outputId": "04bbacf4-044d-4332-f739-2e2b66877c03"
      },
      "source": [
        "valid[0].__dict__"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg_1': ['york',\n",
              "  'university',\n",
              "  'brennan',\n",
              "  'center',\n",
              "  'publish',\n",
              "  'article',\n",
              "  'michael',\n",
              "  'price',\n",
              "  'smart',\n",
              "  'tv',\n",
              "  'scare',\n",
              "  'turn',\n",
              "  'thing',\n",
              "  'myriad',\n",
              "  'disturb',\n",
              "  'feature',\n",
              "  'facial',\n",
              "  'recognition'],\n",
              " 'neg_2': ['friday',\n",
              "  'trade',\n",
              "  'barb',\n",
              "  'conservative',\n",
              "  'ted',\n",
              "  'cruz',\n",
              "  'launch',\n",
              "  'tv',\n",
              "  'ad',\n",
              "  'feature',\n",
              "  'jamiel',\n",
              "  'shaw',\n",
              "  'son',\n",
              "  'murder',\n",
              "  'undocumented',\n",
              "  'migrant'],\n",
              " 'neg_3': ['glower', 'loose', 'divot', 'suggest', '-pron-', 'pitch', 'blame'],\n",
              " 'text': ['go',\n",
              "  'lee',\n",
              "  'brown',\n",
              "  'injury',\n",
              "  'time',\n",
              "  'goal',\n",
              "  'mean',\n",
              "  'accrington',\n",
              "  'score',\n",
              "  'remain',\n",
              "  'bump',\n",
              "  'play',\n",
              "  'offs']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ixOpnt5CLVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "263e15a1-9e57-4400-bb08-167938008130"
      },
      "source": [
        "train[0].__dict__"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'neg_1': ['internet',\n",
              "  'messy',\n",
              "  'fill',\n",
              "  'lot',\n",
              "  'different',\n",
              "  'stuff',\n",
              "  'need',\n",
              "  'conversation'],\n",
              " 'neg_2': ['change', 'football', 'league'],\n",
              " 'neg_3': ['give',\n",
              "  'big',\n",
              "  'advantage',\n",
              "  'campaign',\n",
              "  'ability',\n",
              "  'datum',\n",
              "  'technology',\n",
              "  'target',\n",
              "  'individual',\n",
              "  'voter'],\n",
              " 'text': ['catherine',\n",
              "  'invite',\n",
              "  'lakeside',\n",
              "  'summer',\n",
              "  'house',\n",
              "  'old',\n",
              "  'friend',\n",
              "  'virginia',\n",
              "  'play',\n",
              "  'katherine',\n",
              "  'waterston',\n",
              "  'recuperate']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRU_7HrF-gxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = dataset.split(0.8)\n",
        "train, valid = train.split(0.8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKwWlNG1-NEl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
        "    (train, valid, test),\n",
        "    batch_sizes=(BATCH_SIZE, BATCH_SIZE, BATCH_SIZE),\n",
        "    shuffle=True,\n",
        "    sort_key=lambda x: len(x.text),\n",
        "    device=device\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfEnYr_U_FqE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "3f703931-1c68-4be9-c10b-a1a692f3de16"
      },
      "source": [
        "b = next(iter(valid_iterator))\n",
        "vars(b).keys()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['batch_size', 'dataset', 'fields', 'input_fields', 'target_fields', 'text', 'neg_1', 'neg_2', 'neg_3'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reQyCrXt_RLw",
        "colab_type": "code",
        "outputId": "59eab088-68d1-4013-b183-f91cef244e79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "b = next(iter(train_iterator))\n",
        "vars(b).keys()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['batch_size', 'dataset', 'fields', 'input_fields', 'target_fields', 'text', 'neg_1', 'neg_2', 'neg_3'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYARfK2D_0h9",
        "colab_type": "code",
        "outputId": "1980b66c-d558-4870-8b50-ddecd1b21191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "b.text.size(), b.neg_1.size(), b.neg_2.size(), b.neg_3.size()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 33]),\n",
              " torch.Size([64, 39]),\n",
              " torch.Size([64, 42]),\n",
              " torch.Size([64, 34]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LsY9Jr7zA1y",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHxS0RLJEiRT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwBbIppuzB7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Optimizer = Adam\n",
        "\n",
        "# learning rate 0.001 for 15 epochs and batch size of 50. \n",
        "# We set the number of negative samples per input sample m to 20,\n",
        "# λ to 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUH5W1R4BOh5",
        "colab_type": "text"
      },
      "source": [
        "**Or** just use sentence embedding as an average over word embeddings **[5 points]**:  \n",
        "$z_s = \\frac 1 n \\sum_{i=1}^n e_{w_i}, z_s \\in R^d$ sentence embedding  \n",
        "$e_{w_i} \\in R^d$, token embedding of size d  \n",
        "$n$ - number of tokens in a sentence  \n",
        " \n",
        "$p_t = softmax(W z_s + b), p_t \\in R^K$ topic weights for sentence $s$, with trainable matrix $W \\in R^{dxK}$ and bias vector $b \\in R^K$  \n",
        "$r_s = T^T p_t, r_s \\in R^d$ reconstructed sentence embedding as a weighted sum of topic embeddings   \n",
        "$T \\in R^{Kxd}$ trainable matrix of topic embeddings, K=number of topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZN6Du_eOEl0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, embed_size, topics_size):\n",
        "        super(MyModel, self).__init__()\n",
        "        \n",
        "        self.vocab_size = vocab_size\n",
        "        self.embed_size = embed_size\n",
        "        self.topics_size = topics_size\n",
        "\n",
        "        self.embeddings = nn.Embedding(self.vocab_size, self.embed_size)\n",
        "        self.embeddings.weight.data.copy_(vocab.vectors)\n",
        "        self.embeddings.requires_gra = False  # For now let's freeze them\n",
        "\n",
        "        self.fc1 = nn.Linear(self.embed_size, self.topics_size)  # W\n",
        "        self.fc2 = nn.Linear(self.topics_size, self.embed_size)  # T\n",
        "\n",
        "        self.bias = None\n",
        "\n",
        "\n",
        "    def sentence_embeddings(self, x):\n",
        "        '''\n",
        "        input: (batch_size, seq_length, embed_size)\n",
        "        output: (batch_size, embed_size)\n",
        "        '''\n",
        "        x = torch.sum(x, dim=1)/x.size()[1]\n",
        "        return x\n",
        "\n",
        "    \n",
        "    def forward(self, batch):\n",
        "        \n",
        "        text, neg_1, neg_2, neg_3 = batch.text, batch.neg_1, batch.neg_2, batch.neg_3\n",
        "\n",
        "        text_true = self.sentence_embeddings(self.embeddings(text))\n",
        "        neg_1 = self.sentence_embeddings(self.embeddings(neg_1))\n",
        "        neg_2 = self.sentence_embeddings(self.embeddings(neg_2))\n",
        "        neg_3 = self.sentence_embeddings(self.embeddings(neg_3))\n",
        "\n",
        "        \n",
        "        text_out = self.fc1(text_true)\n",
        "        text_out = F.softmax(text_out, dim=1)\n",
        "        text_out = self.fc2(text_out)\n",
        "\n",
        "        return text_true, text_out, neg_1, neg_2, neg_3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFrK-HFE87g9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fffc4958-346a-4cd8-8928-52544ef75165"
      },
      "source": [
        "model.fc2.weight.size()"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([200, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwtsQNuRuY2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = MyModel(vocab_size=len(vocab), embed_size=200, topics_size=10)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NdY_ERuudTw",
        "colab_type": "code",
        "outputId": "a8539751-913c-4c02-e038-b8c51c7c0a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        }
      },
      "source": [
        "model.forward(b)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.1040,  0.0607,  0.0434,  ..., -0.0655,  0.0050,  0.0481],\n",
              "         [-0.0277, -0.0103,  0.1187,  ..., -0.0986,  0.1300, -0.0005],\n",
              "         [ 0.0428,  0.1004,  0.0653,  ..., -0.0619, -0.0193,  0.1776],\n",
              "         ...,\n",
              "         [-0.0033,  0.0018,  0.0027,  ...,  0.0054, -0.0019, -0.0067],\n",
              "         [-0.0692,  0.0241, -0.0075,  ..., -0.0812,  0.0274, -0.0182],\n",
              "         [-0.1031,  0.0283,  0.0414,  ..., -0.0419,  0.1143,  0.2702]],\n",
              "        device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor([[-2.5620e-01,  3.2627e-01, -2.1972e-01,  ..., -3.5729e-02,\n",
              "           2.6560e-03, -1.6473e-01],\n",
              "         [-2.5265e-01,  3.1814e-01, -2.2743e-01,  ..., -3.3048e-02,\n",
              "           8.6200e-04, -1.6366e-01],\n",
              "         [-2.5449e-01,  3.1818e-01, -2.1674e-01,  ..., -3.3927e-02,\n",
              "          -2.4349e-04, -1.6762e-01],\n",
              "         ...,\n",
              "         [-2.5471e-01,  3.2195e-01, -2.2187e-01,  ..., -3.4323e-02,\n",
              "           1.1400e-03, -1.6472e-01],\n",
              "         [-2.5465e-01,  3.2172e-01, -2.2440e-01,  ..., -3.5722e-02,\n",
              "           8.5251e-04, -1.6517e-01],\n",
              "         [-2.5643e-01,  3.2652e-01, -2.1761e-01,  ..., -3.3648e-02,\n",
              "           3.7695e-03, -1.6231e-01]], device='cuda:0', grad_fn=<AddmmBackward>),\n",
              " tensor([[-0.0962, -0.0131,  0.1313,  ...,  0.0654, -0.0119,  0.0678],\n",
              "         [-0.0400, -0.0052, -0.0057,  ..., -0.0015, -0.0243, -0.0376],\n",
              "         [-0.0363, -0.0843, -0.0621,  ..., -0.1295,  0.0306, -0.0246],\n",
              "         ...,\n",
              "         [-0.1438,  0.0845,  0.0534,  ..., -0.1729, -0.0634, -0.0555],\n",
              "         [-0.0439,  0.0114, -0.0155,  ..., -0.0414, -0.0105, -0.0211],\n",
              "         [ 0.0105,  0.0046, -0.0145,  ..., -0.1018, -0.0192, -0.0465]],\n",
              "        device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor([[ 0.0470, -0.0104,  0.0771,  ..., -0.0794, -0.0006, -0.0069],\n",
              "         [-0.0743, -0.0045,  0.0504,  ..., -0.0589,  0.0584,  0.1955],\n",
              "         [ 0.1742,  0.0460, -0.0298,  ..., -0.0196, -0.0117,  0.2765],\n",
              "         ...,\n",
              "         [ 0.0067,  0.0467,  0.0309,  ...,  0.0278, -0.0037,  0.0470],\n",
              "         [-0.0415,  0.0224,  0.0834,  ..., -0.0094,  0.0195,  0.1736],\n",
              "         [-0.0333, -0.0333,  0.0278,  ...,  0.0115,  0.0177, -0.0050]],\n",
              "        device='cuda:0', grad_fn=<DivBackward0>),\n",
              " tensor([[ 0.3576,  0.0121,  0.0733,  ..., -0.1202, -0.1011,  0.4551],\n",
              "         [ 0.0170,  0.0258,  0.0351,  ..., -0.0021, -0.0361,  0.1883],\n",
              "         [ 0.0466,  0.0810,  0.0216,  ..., -0.0655,  0.0310,  0.1333],\n",
              "         ...,\n",
              "         [ 0.0492,  0.0338,  0.0924,  ..., -0.0309, -0.0691,  0.1246],\n",
              "         [ 0.1364,  0.0219,  0.0793,  ..., -0.0440, -0.1597,  0.2150],\n",
              "         [-0.0512,  0.0501,  0.0922,  ..., -0.1493, -0.0115,  0.0935]],\n",
              "        device='cuda:0', grad_fn=<DivBackward0>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLsARbd7xDLW",
        "colab_type": "code",
        "outputId": "05d3105b-347e-4c6c-a924-615fe0ef0680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "tr, out, n1, n2, n3 = model.forward(b)\n",
        "\n",
        "tr.size(), out.size(), n1.size(), n2.size(), n3.size()"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 200]),\n",
              " torch.Size([64, 200]),\n",
              " torch.Size([64, 200]),\n",
              " torch.Size([64, 200]),\n",
              " torch.Size([64, 200]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGBM5jz9MMmm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc0c6e9b-0634-41f7-f840-0d1519cc37fa"
      },
      "source": [
        "loss_batch = 0 \n",
        "for ind, truth in enumerate(tr): # Проходимся по батчу\n",
        "    # print(truth.size())\n",
        "    temp = 1 - torch.dot(out[ind].T, tr[ind]) + torch.dot(out[ind].T, n1[ind]) + torch.dot(out[ind].T, n2[ind]) + torch.dot(out[ind].T, n3[ind])\n",
        "    # print(temp.size(), temp)\n",
        "    t_max = F.relu(temp)\n",
        "    # print(t_max)\n",
        "    loss_batch += t_max\n",
        "    # break\n",
        "loss_batch / BATCH_SIZE"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0597, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON3ye7y5F1a0",
        "colab_type": "text"
      },
      "source": [
        "**Training objective**:\n",
        "$$ J = \\sum_{s \\in D} \\sum_{i=1}^n max(0, 1-r_s^T z_s + r_s^T n_i) + \\lambda ||T^T T - I ||^2_F  $$\n",
        "where   \n",
        "$m$ random sentences are sampled as negative examples from dataset $D$ for each sentence $s$  \n",
        "$n_i = \\frac 1 n \\sum_{i=j}^n e_{w_j}$ average of word embeddings in the i-th sentence  \n",
        "$||T^T T - I ||_F$ regularizer, that enforces matrix $T$ to be orthogonal  \n",
        "$||A||^2_F = \\sum_{i=1}^N\\sum_{j=1}^M a_{ij}^2, A \\in R^{NxM}$ Frobenius norm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdLN70N9yzbd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://spandan-madan.github.io/A-Collection-of-important-tasks-in-pytorch/\n",
        "\n",
        "class LossFunction(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(LossFunction, self).__init__()\n",
        "\n",
        "    def forward(self, emb_true, emb_pred, n1, n2, n3, T, lambd=1):\n",
        "\n",
        "        loss_batch = 0\n",
        "        for ind, e_true in enumerate(emb_true): # Проходимся по батчу\n",
        "            # print(truth.size())\n",
        "            temp = 1 - torch.dot(emb_pred[ind].T, e_true) + torch.dot(emb_pred[ind].T, n1[ind]) + torch.dot(emb_pred[ind].T, n2[ind]) + torch.dot(emb_pred[ind].T, n3[ind])\n",
        "            # print(temp.size(), temp)\n",
        "            t_max = F.relu(temp)\n",
        "            # print(t_max)\n",
        "            loss_batch += t_max\n",
        "        loss_batch += lambd * torch.norm(torch.mm(T.T, T) - torch.eye(T.size()[1], T.size(1)).to(device))\n",
        "        return loss_batch / BATCH_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF02m-9_Dwz6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff97ac79-b623-44b7-9035-59af1c908ab3"
      },
      "source": [
        "criterion = LossFunction()\n",
        "criterion.to(device)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LossFunction()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiZDGCkqI578",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "def _train_epoch(model, iterator, optimizer, curr_epoch):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    running_loss = 0\n",
        "\n",
        "    n_batches = len(iterator)\n",
        "    iterator = tqdm_notebook(iterator, total=n_batches, desc='epoch %d' % (curr_epoch), leave=True)\n",
        "\n",
        "    for i, batch in enumerate(iterator):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        text_true, text_out, neg_1, neg_2, neg_3 = model(batch)\n",
        "        loss = criterion(text_true, text_out, neg_1, neg_2, neg_3, model.fc2.weight)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        curr_loss = loss.item()\n",
        "        \n",
        "        loss_smoothing = i / (i+1)\n",
        "        running_loss = loss_smoothing * running_loss + (1 - loss_smoothing) * curr_loss\n",
        "\n",
        "        train_losses.append(running_loss)\n",
        "        iterator.set_postfix(loss='%.5f' % running_loss)\n",
        "\n",
        "    return running_loss\n",
        "\n",
        "\n",
        "def _test_epoch(model, iterator):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "\n",
        "    n_batches = len(iterator)\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            text_true, text_out, neg_1, neg_2, neg_3 = model(batch)\n",
        "            loss = criterion(text_true, text_out, neg_1, neg_2, neg_3, model.fc2.weight)\n",
        "            epoch_loss += loss.data.item()\n",
        "            valid_losses.append(loss)\n",
        "\n",
        "    return epoch_loss / n_batches\n",
        "\n",
        "\n",
        "def nn_train(model, train_iterator, valid_iterator, optimizer, n_epochs=100,\n",
        "          scheduler=None, early_stopping=0):\n",
        "\n",
        "    prev_loss = 100500\n",
        "    es_epochs = 0\n",
        "    best_epoch = None\n",
        "    history = pd.DataFrame()\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = _train_epoch(model, train_iterator, optimizer, epoch)\n",
        "        valid_loss = _test_epoch(model, valid_iterator)\n",
        "        # scheduler.step(valid_loss)\n",
        "\n",
        "        valid_loss = valid_loss\n",
        "        print('validation loss %.5f' % valid_loss)\n",
        "\n",
        "        record = {'epoch': epoch, 'train_loss': train_loss, 'valid_loss': valid_loss}\n",
        "        history = history.append(record, ignore_index=True)\n",
        "\n",
        "        if early_stopping > 0:\n",
        "            if valid_loss > prev_loss:\n",
        "                es_epochs += 1\n",
        "            else:\n",
        "                es_epochs = 0\n",
        "\n",
        "            if es_epochs >= early_stopping:\n",
        "                best_epoch = history[history.valid_loss == history.valid_loss.min()].iloc[0]\n",
        "                print('Early stopping! best epoch: %d val %.5f' % (best_epoch['epoch'], best_epoch['valid_loss']))\n",
        "                break\n",
        "\n",
        "            prev_loss = min(prev_loss, valid_loss)\n",
        "\n",
        "# nn_train(model, train_loader, valid_loader, optimizer, n_epochs=100) # Удалила вывод, т.к. он длинный, график лосса ниже"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1nm5k9W9pQ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nvcBP2T9b41",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "92a1d77b98de4c3b82efc0e005b724bd",
            "e92f2f17a8234662a23759b3c02fc4da",
            "7135bf419172456f95a0d6de2d5fd945",
            "330bb89a2ba94dbb923ecd3f01f5a3d3",
            "3acca2322a0a4c1090a8638bfacbbba3",
            "baabd368226e4ceda82bb4a3f3a593b1",
            "25a04fc1a1424a42bb3f709de2bb23b2",
            "91195fdb9c3742ea9c477634421de74f",
            "3afeba473a544877bc24dbcc2b6e2b29",
            "8190c6d6a438442d9b0b72a4c68383b7",
            "021b4bad7c9745cda52db3ea8ab09ac7",
            "1e128dfc600b4b35990090824b88a23e",
            "a0c70f0e36734b1384ed3b3d03756ac2",
            "40b552b3d56943689022eb84ccf3c366",
            "bc1a696a09464904be8dad41c777e948",
            "0b55ab96d57d44c5ac84fc059282114a",
            "fd54751d2e1643029960d79834c2601d",
            "aede1b3c16164cb3bfaca2c7214142fd",
            "d26e5f496430424d8852f4acc1ced5d6",
            "32c8efbc7b46433bb946fe9389e64541",
            "79d51232ab3e418e97d9e07ea1ac7d08",
            "273f5e2fdaec4ba6a041136f61cba3c6",
            "0ff1eeddd57344abb48f5b3ea5e6e759",
            "04c64944ad834bbda58e92335ed7a5cb"
          ]
        },
        "outputId": "4c1a4017-41f6-4a70-8ae0-abd638eaaa9e"
      },
      "source": [
        "nn_train(model, train_iterator, valid_iterator, optimizer, n_epochs=15) # Удалила вывод, т.к. он длинный, график лосса ниже"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92a1d77b98de4c3b82efc0e005b724bd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch 0', max=1834, style=ProgressStyle(description_width='in…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation loss nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3afeba473a544877bc24dbcc2b6e2b29",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch 1', max=1834, style=ProgressStyle(description_width='in…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "validation loss nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd54751d2e1643029960d79834c2601d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='epoch 2', max=1834, style=ProgressStyle(description_width='in…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-29e3df461286>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnn_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Удалила вывод, т.к. он длинный, график лосса ниже\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-113-b23d773c8fbd>\u001b[0m in \u001b[0;36mnn_train\u001b[0;34m(model, train_iterator, valid_iterator, optimizer, n_epochs, scheduler, early_stopping)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_test_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# scheduler.step(valid_loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-113-b23d773c8fbd>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(model, iterator, optimizer, curr_epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtext_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le2O3ovB99Gm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5Wg8Gj_zCYa",
        "colab_type": "text"
      },
      "source": [
        "# Topic CoHerence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sg9mNs1uzEza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}