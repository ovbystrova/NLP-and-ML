{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_assignment_5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zU-22kO4PNq5",
        "8NGR9kAWetgl"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMGDBbGSho8x",
        "colab_type": "text"
      },
      "source": [
        "# Assignment 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5eXBekihyDo",
        "colab_type": "text"
      },
      "source": [
        "Build CNN model for sentiment analysis (binary classification) of IMDB Reviews (https://www.kaggle.com/utathya/imdb-review-dataset). You can use data with label=\"unsup\" for pretraining of embeddings. Here you are forbidden to use test dataset for pretraining of embeddings.\n",
        "Your quality metric is accuracy score on test dataset. Look at \"type\" column for train/test split.\n",
        "You can use pretrained embeddings from external sources.\n",
        "You have to provide data for trials with different hyperparameter values.\n",
        "\n",
        "You have to beat following baselines:\n",
        "[3 points] acc = 0.75\n",
        "[5 points] acc = 0.8\n",
        "[8 points] acc = 0.9\n",
        "\n",
        "[2 points] for using unsupervised data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SKbq3nowr4fy",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "idd = '1smuY3sJJ6wcL28i0QcBSlnEsimB5holu'\n",
        "downloaded_ = drive.CreateFile({'id':idd}) \n",
        "downloaded_.GetContentFile('imdb_master.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ya8KscvDr5BQ",
        "outputId": "cf25b7c2-de7e-4359-9238-f10cec287e3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import spacy\n",
        "from spacy.symbols import ORTH\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "import torch\n",
        "from torchtext.data import Field, LabelField, BucketIterator, TabularDataset, Iterator, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "spacy_en = spacy.load('en')\n",
        "spacy_en.tokenizer.add_special_case(\"don't\", [{ORTH: \"do\"}, {ORTH: \"not\"}])\n",
        "spacy_en.tokenizer.add_special_case(\"didn't\", [{ORTH: \"did\"}, {ORTH: \"not\"}]) #adding special case so that tokenizer(\"\"\"don't\"\"\") != 'do'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU-22kO4PNq5",
        "colab_type": "text"
      },
      "source": [
        "#0. Preprocessing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR0ThTY8ufuI",
        "colab_type": "code",
        "outputId": "0698e168-3c2e-4ee6-e130-5a374db7b3ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df = pd.read_csv('imdb_master.csv', sep=',', encoding= 'latin-1',  index_col=0)\n",
        "df = df.drop(columns=['file'])\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>test</td>\n",
              "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>test</td>\n",
              "      <td>This is an example of why the majority of acti...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>test</td>\n",
              "      <td>First of all I hate those moronic rappers, who...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>test</td>\n",
              "      <td>Not even the Beatles could write songs everyon...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>test</td>\n",
              "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                             review label\n",
              "0  test  Once again Mr. Costner has dragged out a movie...   neg\n",
              "1  test  This is an example of why the majority of acti...   neg\n",
              "2  test  First of all I hate those moronic rappers, who...   neg\n",
              "3  test  Not even the Beatles could write songs everyon...   neg\n",
              "4  test  Brass pictures (movies is not a fitting word f...   neg"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbMAX-Htenf",
        "colab_type": "code",
        "outputId": "6ee36561-e889-4cc1-8461-a2e20abcbcf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#for future embedding training\n",
        "mask = df['type'] == 'train'\n",
        "df_train_unsup = df[mask]\n",
        "print(len(df_train_unsup))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTC8Bl50aZ5E",
        "colab_type": "code",
        "outputId": "517c285d-8258-42ac-f9d0-1943e0d1f3ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Let's separate 'unsup' elements for now, but we will use them later\n",
        "mask = df['label'] == 'unsup'\n",
        "df_unsup = df[mask]\n",
        "df = df[~mask]\n",
        "len(df_unsup), len(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 50000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pa1jFy_a9bF",
        "colab_type": "code",
        "outputId": "b7b66deb-1a60-4071-bef5-8e52b9e40899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#making sure that we don't have 'unsup' lables in test\n",
        "mask = df_unsup['type'] == 'test'\n",
        "len(df_unsup[mask])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUf41SV-cndV",
        "colab_type": "code",
        "outputId": "d97a043c-9b92-4f85-bade-bda4c044be2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#now we split our labled data\n",
        "mask = df['type'] == 'train'\n",
        "df_train = df[mask]\n",
        "df_test = df[~mask]\n",
        "len(df_train), len(df_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKBWdDUEXPlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train.to_csv(\"dataset_train.csv\", index=False)\n",
        "df_test.to_csv(\"dataset_test.csv\", index=False)\n",
        "df_unsup.to_csv(\"dataset_unsup.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-PecH5rPxSX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(text):\n",
        "    return [tok.lemma_ for tok in spacy_en.tokenizer(text) if tok.text.isalpha()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXnf0izvtzn7",
        "colab_type": "code",
        "outputId": "a782c5c8-7d93-4fef-e60f-496c3bc9bb26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#Using 'unsup'+'train' data to pretrain custom embeddings / no 'tets' data\n",
        "\n",
        "tokenized_unsup = list(df_train_unsup['review'].apply(tokenizer))\n",
        "w2v_model = Word2Vec(tokenized_unsup, size=100)\n",
        "weights = torch.FloatTensor(w2v_model.wv.vectors)\n",
        "w2v_model.wv.save_word2vec_format('pretrained_embeddings')\n",
        "vectors = Vectors(name='pretrained_embeddings', cache='./')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhv5hIthSMdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_VOCAB_SIZE = 50000\n",
        "classes={'neg': 0, 'pos': 1}\n",
        "\n",
        "\n",
        "REVIEW = Field(sequential=True, include_lengths=False, batch_first=True, tokenize=tokenizer, pad_first=True, lower=True, eos_token='<eos>') \n",
        "LABEL = LabelField(dtype=torch.float, use_vocab=True, preprocessing=lambda x: classes[x])\n",
        "\n",
        "train = TabularDataset('dataset_train.csv', \n",
        "                                format='csv', fields=[(None,None),('review', REVIEW),('label', LABEL)], \n",
        "                                skip_header=True)\n",
        "\n",
        "test = TabularDataset('dataset_test.csv', \n",
        "                                format='csv', fields=[(None,None),('review', REVIEW),('label', LABEL)], \n",
        "                                skip_header=True)\n",
        "\n",
        "dataset_unsup = TabularDataset('dataset_unsup.csv', \n",
        "                                format='csv', fields=[(None,None),('review', REVIEW), (None, None)], \n",
        "                                skip_header=True)\n",
        "\n",
        "REVIEW.build_vocab(train, dataset_unsup, min_freq=2, vectors=vectors,\n",
        "                   unk_init = torch.Tensor.normal_, max_size=MAX_VOCAB_SIZE) #we use 'unsup' data to build vocab/emb, but not test data\n",
        "LABEL.build_vocab(train, dataset_unsup)\n",
        "vocab = REVIEW.vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVN99RXXj1-v",
        "colab_type": "code",
        "outputId": "3bf7bbdc-5c81-4083-a8f2-a3edf4b4dd26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print('Vocab size:', len(REVIEW.vocab.itos))\n",
        "REVIEW.vocab.itos[:10]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size: 50003\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<unk>', '<pad>', '<eos>', 'the', 'be', 'a', 'and', 'of', 'to', 'in']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRXenE3tmOkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#I tried to use train/test split with different proportions but the model is so overfiting that I decided to just train model on whole train dataset and test model after every epoch\n",
        "#train, valid = train.split(0.95, stratified=True, random_state=np.random.seed(SEED))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXotmgW4ydqk",
        "colab_type": "code",
        "outputId": "acd10b81-751d-41ec-eb4e-e10af82563cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "print(train[0].review)\n",
        "print(train[0].label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['story', 'of', 'a', 'man', 'who', 'have', 'unnatural', 'feeling', 'for', 'a', 'pig', 'starts', 'out', 'with', 'a', 'open', 'scene', 'that', 'be', 'a', 'terrific', 'example', 'of', 'absurd', 'comedy', 'a', 'formal', 'orchestra', 'audience', 'be', 'turn', 'into', 'a', 'insane', 'violent', 'mob', 'by', 'the', 'crazy', 'chantings', 'of', '-pron-', 'singer', 'unfortunately', 'it', 'stay', 'absurd', 'the', 'whole', 'time', 'with', 'no', 'general', 'narrative', 'eventually', 'make', 'it', 'just', 'too', 'off', 'putt', 'even', 'that', 'from', 'the', 'era', 'should', 'be', 'turn', 'off', 'the', 'cryptic', 'dialogue', 'would', 'make', 'shakespeare', 'seem', 'easy', 'to', 'a', '3', 'grader', 'on', 'a', 'technical', 'level', '-pron-', 'well', 'than', 'you', 'may', 'think', 'with', 'some', 'good', 'cinematography', 'by', 'future', 'great', 'vilmos', 'zsigmond', 'future', 'star', 'sally', 'kirkland', 'and', 'frederic', 'forrest', 'can', 'be', 'see', 'briefly']\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DualFUVmWXZ",
        "colab_type": "text"
      },
      "source": [
        "# 1. MyModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT7KYrWtmYaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, embed_size, hidden_size, kernels, padding_idx):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=padding_idx)\n",
        "        self.embedding.weight.data.copy_(vocab.vectors)        \n",
        "        self.convs = nn.ModuleList([nn.Conv1d(embed_size, hidden_size, k) for k in kernels])\n",
        "        #self.dropout = nn.Dropout(dropout)        \n",
        "        self.fc = nn.Linear(hidden_size * len(kernels), 1)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.transpose(1,2)\n",
        "        \n",
        "        concatenated = []\n",
        "        for conv in self.convs:\n",
        "            z = conv(x)\n",
        "            z = F.relu(z)\n",
        "            z = F.max_pool1d(z, kernel_size=z.size(2)).squeeze(2)\n",
        "            concatenated.append(z)\n",
        "            \n",
        "        x = torch.cat(concatenated, 1)\n",
        "        #x = self.dropout(x)\n",
        "        x = self.fc(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-QM6xuXmmAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(batch_size, hidden_size, kernels):\n",
        "    \"\"\"\n",
        "    Функция определяет модель по заданным гиперпараметрам и возвращает итераторы с заданным batch_size, а также оптимайзер и критерий\n",
        "    \"\"\"\n",
        "    torch.cuda.empty_cache()    \n",
        "\n",
        "    padding_idx = REVIEW.vocab.stoi[REVIEW.pad_token]\n",
        "    \n",
        "    model = MyModel(len(REVIEW.vocab.itos),\n",
        "                    embed_size=100,\n",
        "                    hidden_size=hidden_size,\n",
        "                    kernels=kernels,\n",
        "                    padding_idx = padding_idx\n",
        "                )\n",
        "\n",
        "    train_iterator, test_iterator = BucketIterator.splits(\n",
        "        (train, test),\n",
        "        batch_sizes=(batch_size, batch_size),\n",
        "        shuffle=True,\n",
        "        sort_key=lambda x: len(x.review),\n",
        "    )\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "    return model, train_iterator, test_iterator, optimizer, criterion"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYNMVE4VD1_J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy_score(preds, y):\n",
        "    preds = torch.round(torch.sigmoid(preds))\n",
        "    preds = (preds == y).float()\n",
        "    accuracy = preds.sum() / len(preds)\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV5MsPR6cIVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_model(model, test_iterator):\n",
        "    test_acc = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for item in test_iterator:\n",
        "            x = item.review\n",
        "            y = item.label\n",
        "            preds = model(x).squeeze(1)\n",
        "            test_acc.append(accuracy_score(preds, y))\n",
        "    test_acc = np.mean(test_acc) \n",
        "    return print('Test accuracy: {}'.format(np.mean(test_acc)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgNW1X-btpe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_cnn(model, train_iterator, test_iterator, criterion, device, n_epochs=20):\n",
        "    \n",
        "    history = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        train_loss = []\n",
        "        train_acc = []\n",
        "        model.train()\n",
        "\n",
        "    \n",
        "        for item in tqdm(train_iterator):\n",
        "            x = item.review\n",
        "            y = item.label\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(x).squeeze(1)\n",
        "            loss = criterion(preds, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss.append(loss.data.detach().item())\n",
        "            train_acc.append(accuracy_score(preds, y))\n",
        "\n",
        "        train_loss = np.mean(train_loss)\n",
        "        train_acc = np.mean(train_acc)\n",
        "\n",
        "        model.eval()\n",
        "        test_model(model, test_iterator)\n",
        "\n",
        "\n",
        "        print('Epoch: {}. Train loss: {:.3f}. Train accuracy: {:.3f}.'.format(\n",
        "            epoch, train_loss, train_acc))        \n",
        "        \n",
        "        history.append({\n",
        "            'epoch': epoch,\n",
        "            'train_loss': train_loss,\n",
        "            'train_acc': train_acc,\n",
        "        })\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            torch.save(model.state_dict(), '/content/model_test')\n",
        "\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBtlmhz1hTKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_tqdm():\n",
        "    for instance in list(tqdm._instances): \n",
        "        tqdm._decr_instances(instance)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Lc7dygjn-I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_parameters(model):\n",
        "    params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    return print(f'The model has {params:,} trainable parameters')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pADiy0nFeQHX",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparams "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrW8tlieeTTe",
        "colab_type": "text"
      },
      "source": [
        "Попробуем руками посмотреть/подобрать гиперпараметры. Для этого создадим несколько моделей с разными наборами гиперпараметров и выберем."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVm1hW4fedT5",
        "colab_type": "text"
      },
      "source": [
        "Пойдем по жадному пути. Сначала выберем kernels, затем batch_size, затем hidden_state. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHsXuDu5euaZ",
        "colab_type": "code",
        "outputId": "59afbe43-d7f8-438e-87ee-4ec967bb1590",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "#kernels = [2,3,4,5] - падает коллаб\n",
        "clean_tqdm()\n",
        "model, train_iterator, test_iterator, optimizer, criterion = create_model(64, 128, [2,3,4,5])\n",
        "count_parameters(model)\n",
        "history = train_cnn(model, train_iterator, test_iterator,\n",
        "          criterion, device='cpu', n_epochs=2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The model has 5,180,525 trainable parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 48%|████▊     | 189/391 [02:30<02:30,  1.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b709b7aacf57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcount_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m history = train_cnn(model, train_iterator, test_iterator,\n\u001b[0;32m----> 5\u001b[0;31m           criterion, device='cpu', n_epochs=2)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-b9689599d393>\u001b[0m in \u001b[0;36mtrain_cnn\u001b[0;34m(model, train_iterator, test_iterator, criterion, device, n_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW6BJYRle1zL",
        "colab_type": "code",
        "outputId": "81f00b5e-67a3-4b76-c589-ae5aa5d2c7c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "#kernels = [2,3]\n",
        "clean_tqdm()\n",
        "model, train_iterator, test_iterator, optimizer, criterion = create_model(64, 128, [2,3])\n",
        "count_parameters(model)\n",
        "history = train_cnn(model, train_iterator, test_iterator,\n",
        "          criterion,  device='cpu', n_epochs=2)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\r  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The model has 5,064,813 trainable parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [02:19<00:00,  2.75it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8735293745994568\n",
            "Epoch: 0. Train loss: 0.383. Train accuracy: 0.827.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [02:21<00:00,  2.81it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8704763650894165\n",
            "Epoch: 1. Train loss: 0.255. Train accuracy: 0.897.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJLPyTfMrmyS",
        "colab_type": "code",
        "outputId": "64d48b78-2dff-423b-8c8d-25f1f0f5fee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "#kernels = [2,3, 4]\n",
        "clean_tqdm()\n",
        "model, train_iterator,  test_iterator, optimizer,  criterion = create_model(64, 128, [2,3,4])\n",
        "count_parameters(model)\n",
        "history = train_cnn(model, train_iterator, test_iterator,\n",
        "          criterion,  device='cpu', n_epochs=2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "The model has 5,116,269 trainable parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [03:31<00:00,  1.75it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8779650926589966\n",
            "Epoch: 0. Train loss: 0.374. Train accuracy: 0.830.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [03:37<00:00,  1.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8923993110656738\n",
            "Epoch: 1. Train loss: 0.238. Train accuracy: 0.905.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvwwNke7GlOW",
        "colab_type": "text"
      },
      "source": [
        "Возьмем kernels = [ 2,3,4] - коллаб не падает. метрики приличные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QV1FrfRyfp1u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# now we check batch_size = 128 - падает коллаб\n",
        "clean_tqdm()\n",
        "model, train_iterator, test_iterator, optimizer,  criterion = create_model(128, 128, [2,3,4])\n",
        "history = train_cnn(model, train_iterator, test_iterator,\n",
        "          criterion, device='cpu', n_epochs=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifayvEf4f8YM",
        "colab_type": "code",
        "outputId": "8236ed51-2755-4116-a39d-46eb53dd3f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "#hidden_size = 64\n",
        "clean_tqdm()\n",
        "model, train_iterator, test_iterator, optimizer,  criterion = create_model(64, 64, [2,3,4])\n",
        "history = train_cnn(model, train_iterator, test_iterator,\n",
        "          criterion,  device='cpu', n_epochs=2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [02:22<00:00,  2.46it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8799952268600464\n",
            "Epoch: 0. Train loss: 0.392. Train accuracy: 0.820.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [02:20<00:00,  2.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8656089901924133\n",
            "Epoch: 1. Train loss: 0.253. Train accuracy: 0.897.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zq4BaA8xiZUm",
        "colab_type": "text"
      },
      "source": [
        "Берем hidden_size = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHKUJwq3gK3q",
        "colab_type": "text"
      },
      "source": [
        "Итого, лучшая модель будет такая (я запустила все ячейки выше пару раз, потом уже пропускала этот этап, чтобы не тратить время, сразу брала данные параметры): \n",
        "\n",
        "*   batch_size: 64\n",
        "*   hidden_size: 128\n",
        "*   kernels: [2,3,4]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBt5Bt4rtkZM",
        "colab_type": "text"
      },
      "source": [
        "# 3. Training and evaluating our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB1D0G2Wgq8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model , train_iterator,  test_iterator, optimizer,criterion = create_model(64, 128, [2,3,4])\n",
        "model.embedding.weight.data.copy_(REVIEW.vocab.vectors);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_zhqf1GnA9I",
        "colab_type": "code",
        "outputId": "8f6e8fd9-1977-4f37-d5a1-7a4e7b333570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "count_parameters(model)\n",
        "model"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 5,116,269 trainable parameters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MyModel(\n",
              "  (embedding): Embedding(50003, 100, padding_idx=1)\n",
              "  (convs): ModuleList(\n",
              "    (0): Conv1d(100, 128, kernel_size=(2,), stride=(1,))\n",
              "    (1): Conv1d(100, 128, kernel_size=(3,), stride=(1,))\n",
              "    (2): Conv1d(100, 128, kernel_size=(4,), stride=(1,))\n",
              "  )\n",
              "  (fc): Linear(in_features=384, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yz_gR8AOxPHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "190d0ebb-46db-462f-a29f-344f25c0f59d"
      },
      "source": [
        "#model.load_state_dict(torch.load('model_test (4)'))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqTrx2We0VT1",
        "colab_type": "code",
        "outputId": "7dbe0615-d987-44d0-c84d-374ef83c34e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        }
      },
      "source": [
        "clean_tqdm()\n",
        "history = train_cnn(model, train_iterator,test_iterator,\n",
        "          criterion,  device='cpu', n_epochs=11)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:26<00:00,  1.37it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8792838454246521\n",
            "Epoch: 0. Train loss: 0.391. Train accuracy: 0.819.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:23<00:00,  1.58it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8961237072944641\n",
            "Epoch: 1. Train loss: 0.244. Train accuracy: 0.903.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:30<00:00,  1.02s/it]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8997601866722107\n",
            "Epoch: 2. Train loss: 0.175. Train accuracy: 0.932.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:33<00:00,  1.11it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.8885709643363953\n",
            "Epoch: 3. Train loss: 0.110. Train accuracy: 0.964.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:31<00:00,  1.17it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.891104519367218\n",
            "Epoch: 4. Train loss: 0.058. Train accuracy: 0.988.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:33<00:00,  1.38it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9000160098075867\n",
            "Epoch: 5. Train loss: 0.025. Train accuracy: 0.998.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:33<00:00,  1.29it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9013347029685974\n",
            "Epoch: 6. Train loss: 0.011. Train accuracy: 1.000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:32<00:00,  1.15it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.901702344417572\n",
            "Epoch: 7. Train loss: 0.005. Train accuracy: 1.000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:35<00:00,  1.36it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.90115886926651\n",
            "Epoch: 8. Train loss: 0.003. Train accuracy: 1.000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:34<00:00,  1.48it/s]\n",
            "  0%|          | 0/391 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9010789394378662\n",
            "Epoch: 9. Train loss: 0.002. Train accuracy: 1.000.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 391/391 [04:33<00:00,  1.38it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9010229706764221\n",
            "Epoch: 10. Train loss: 0.002. Train accuracy: 1.000.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P23Xizt7dL5Z",
        "colab_type": "code",
        "outputId": "103f9333-a3bb-4fa9-f001-8114bbaf2944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy = test_model(model, test_iterator)\n",
        "test_accuracy"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9010229706764221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ibCCPNljy9M",
        "colab_type": "text"
      },
      "source": [
        "#4. More 'unsup' data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LsFDB7zL4Um",
        "colab_type": "text"
      },
      "source": [
        "Идея простая: Берем две модели (TextBlob и SentimentIntensityAnalyzer), смотрим что они предсказывают для unsup данных. Если предсказания совпадают, берем, если нет - выкидываем. Но оказалось, что вторая модель большинство текстов определяет как нейтральные. Поэтому родилась такая идея: взять предсказание модели, взять TextBlob и сравнить. Если совпадают - добавляем в обучение."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ItSHrVUIL5bH",
        "colab_type": "code",
        "outputId": "ebc6fe95-7ab0-4326-87a8-6b5a32c34b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!pip install vaderSentiment"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 25.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VavgUyrOL-XG",
        "colab_type": "code",
        "outputId": "4fa61855-663a-4445-e6a6-6317d1be3f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YTGmPANL_Mr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def SIA_fill(sentence):\n",
        "    sentence = ' '.join(tokenizer(sentence))\n",
        "    analyzer = SentimentIntensityAnalyzer()\n",
        "    vs = analyzer.polarity_scores(sentence)\n",
        "    neg = vs['neg']\n",
        "    pos = vs['pos']\n",
        "    score = 'pos' if score > 0 else 'neg'\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iIYmcrBMBPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def TextBlob_fill(sentence):\n",
        "    blob = TextBlob(sentence)\n",
        "    sentence = ' '.join(tokenizer(sentence))\n",
        "    score = blob.sentences[0].sentiment.polarity\n",
        "    score = 'pos' if score > 0 else 'neg'\n",
        "    return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rWQJZDxR1Di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fill(model, unsup_iterator):\n",
        "    model.eval()\n",
        "    labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for item in unsup_iterator:\n",
        "            x = item.review\n",
        "            preds = model(x).squeeze(1)\n",
        "            preds = torch.round(torch.sigmoid(preds))\n",
        "            labels.extend(preds.int().tolist())\n",
        "    return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYaNtyBd2jf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unsup_iterator = BucketIterator(\n",
        "        dataset_unsup,\n",
        "        batch_size=64,\n",
        "        shuffle=False,\n",
        "        sort_key=lambda x: len(x.review),\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fyc7_ZDjMDf_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_to_add = model_fill(model, unsup_iterator)\n",
        "df_unsup['label_model'] = labels_to_add\n",
        "df_unsup['label_textblob'] = df_unsup['review'].apply(TextBlob_fill) #TextBlob\n",
        "#df_unsup['label2'] = df_unsup['review'].apply(SIA_fill) #SentimentIntensityAnalyzer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ3L9DeSvhqa",
        "colab_type": "code",
        "outputId": "cfc76892-3482-4d5b-ab18-538c1058f7cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "#Заполняем поле label лейблами, если они совпадают для модели и textblob\n",
        "def compare_and_fill(version1, version2):\n",
        "    if (version1 == 'neg' and  version2 == 0) or (version1 == 'pos' and  version2 == 1) :\n",
        "        result = 'neg' if version1 is 'neg' else 'pos'\n",
        "    else:\n",
        "        result = 'different'\n",
        "    return result\n",
        "\n",
        "for i, row in df_unsup.iterrows():\n",
        "    result = compare_and_fill(row.label_textblob, row.label_model)\n",
        "    df_unsup.at[i, 'label'] = result\n",
        "df_unsup.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>label_model</th>\n",
              "      <th>label_textblob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50000</th>\n",
              "      <td>train</td>\n",
              "      <td>I admit, the great majority of films released ...</td>\n",
              "      <td>pos</td>\n",
              "      <td>1</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50001</th>\n",
              "      <td>train</td>\n",
              "      <td>Take a low budget, inexperienced actors doubli...</td>\n",
              "      <td>neg</td>\n",
              "      <td>0</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50002</th>\n",
              "      <td>train</td>\n",
              "      <td>Everybody has seen 'Back To The Future,' right...</td>\n",
              "      <td>different</td>\n",
              "      <td>0</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50003</th>\n",
              "      <td>train</td>\n",
              "      <td>Doris Day was an icon of beauty in singing and...</td>\n",
              "      <td>pos</td>\n",
              "      <td>1</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50004</th>\n",
              "      <td>train</td>\n",
              "      <td>After a series of silly, fun-loving movies, 19...</td>\n",
              "      <td>different</td>\n",
              "      <td>1</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        type  ... label_textblob\n",
              "50000  train  ...            pos\n",
              "50001  train  ...            neg\n",
              "50002  train  ...            pos\n",
              "50003  train  ...            pos\n",
              "50004  train  ...            neg\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbGeGD6IMm6q",
        "colab_type": "code",
        "outputId": "5656e696-8b75-48a3-b6f2-c90e16c22c4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "mask = df_unsup['label'] == 'different'\n",
        "print(len(df_unsup[mask]))\n",
        "print(len(df_unsup[~mask]))\n",
        "df_unsup_to_work = df_unsup[~mask]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "18539\n",
            "31461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-akHpF0MpWV",
        "colab_type": "code",
        "outputId": "4dce2a47-7191-45fc-e575-3047bc44ea1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        "#31к лейблов совпадают, будем работ\n",
        "mask = df_unsup_to_work['label'] == 'pos'\n",
        "print(len(df_unsup_to_work[mask]))\n",
        "print(len(df_unsup_to_work[~mask]))\n",
        "df_unsup_to_work.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16515\n",
            "14946\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "      <th>label_model</th>\n",
              "      <th>label_textblob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50000</th>\n",
              "      <td>train</td>\n",
              "      <td>I admit, the great majority of films released ...</td>\n",
              "      <td>pos</td>\n",
              "      <td>1</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50001</th>\n",
              "      <td>train</td>\n",
              "      <td>Take a low budget, inexperienced actors doubli...</td>\n",
              "      <td>neg</td>\n",
              "      <td>0</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50003</th>\n",
              "      <td>train</td>\n",
              "      <td>Doris Day was an icon of beauty in singing and...</td>\n",
              "      <td>pos</td>\n",
              "      <td>1</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50005</th>\n",
              "      <td>train</td>\n",
              "      <td>This isn't exactly a musical, but it almost se...</td>\n",
              "      <td>pos</td>\n",
              "      <td>1</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50007</th>\n",
              "      <td>train</td>\n",
              "      <td>In the 1950's there were many film boigraphies...</td>\n",
              "      <td>pos</td>\n",
              "      <td>1</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        type  ... label_textblob\n",
              "50000  train  ...            pos\n",
              "50001  train  ...            neg\n",
              "50003  train  ...            pos\n",
              "50005  train  ...            pos\n",
              "50007  train  ...            pos\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-iGypt7pt2I",
        "colab_type": "text"
      },
      "source": [
        "Баланс классов нормальный. Работаем."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPXWy8b9p2KD",
        "colab_type": "code",
        "outputId": "113f666a-3b3d-4937-acd0-33d1b159c4a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "df_unsup_to_work = df_unsup_to_work.drop(columns=['label_model', 'label_textblob'])\n",
        "df_unsup_to_work.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>50000</th>\n",
              "      <td>train</td>\n",
              "      <td>I admit, the great majority of films released ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50001</th>\n",
              "      <td>train</td>\n",
              "      <td>Take a low budget, inexperienced actors doubli...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50003</th>\n",
              "      <td>train</td>\n",
              "      <td>Doris Day was an icon of beauty in singing and...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50005</th>\n",
              "      <td>train</td>\n",
              "      <td>This isn't exactly a musical, but it almost se...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50007</th>\n",
              "      <td>train</td>\n",
              "      <td>In the 1950's there were many film boigraphies...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        type                                             review label\n",
              "50000  train  I admit, the great majority of films released ...   pos\n",
              "50001  train  Take a low budget, inexperienced actors doubli...   neg\n",
              "50003  train  Doris Day was an icon of beauty in singing and...   pos\n",
              "50005  train  This isn't exactly a musical, but it almost se...   pos\n",
              "50007  train  In the 1950's there were many film boigraphies...   pos"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg7vmQPLP4O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_unsup_to_work.to_csv(\"unsup_labels.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NT5Vz9HMzu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_unsup = TabularDataset('unsup_labels.csv', \n",
        "                                format='csv', fields=[(None, None), ('review', REVIEW), ('label', LABEL)], \n",
        "                                skip_header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4IHlXAYM2V3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#let's concatenate train and unsup data\n",
        "ds_concat  = train + dataset_unsup\n",
        "list_of_ex = [x for x in ds_concat]\n",
        "new_ds = Dataset(list_of_ex, [('review', REVIEW), ('label', LABEL)])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFIjBq8mM4c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "unsup_iterator = BucketIterator(\n",
        "        new_ds,\n",
        "        batch_size=64,\n",
        "        shuffle=True,\n",
        "        sort_key=lambda x: len(x.review),\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPKTprcIM6is",
        "colab_type": "code",
        "outputId": "d0674d52-2f4c-4442-9c0c-7487335fc900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "clean_tqdm()\n",
        "history = train_cnn(model, unsup_iterator,  test_iterator,\n",
        "          criterion,  device='cpu', n_epochs=6)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 65%|██████▍   | 573/883 [05:13<02:57,  1.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-0900f77e9849>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m history = train_cnn(model, unsup_iterator,  test_iterator,\n\u001b[0;32m----> 2\u001b[0;31m           criterion,  device='cpu', n_epochs=6)\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-b9689599d393>\u001b[0m in \u001b[0;36mtrain_cnn\u001b[0;34m(model, train_iterator, test_iterator, criterion, device, n_epochs)\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \"\"\"\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjJrtM2LNppd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#У меня падает коллаб. но 0.9 уже есть и unsup data уже используется"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIFnaaEqM8oT",
        "colab_type": "code",
        "outputId": "bd66f227-7002-4e1c-ec0c-21f7fbed9025",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_accuracy = test_model(model, test_iterator)\n",
        "test_accuracy"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy: 0.9010229706764221\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}